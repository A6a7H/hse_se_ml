{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнила команда: __Терлыч Никита__, __Сунцев Максим__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание лучшей модели\n",
    "\n",
    "Использованые фичи:\n",
    "\n",
    "- Категориальные: ['category_id','sold_mode', 'product_type', 'payment_available', \n",
    "                    'subcategory_id', 'city', 'delivery_available', 'img_num', 'region']\n",
    "- Непрерывные: ['lat', 'long','price']\n",
    "- Текстовые: ['desc_text', 'name_text']\n",
    "\n",
    "Категориальные фичи были преобработаны и заменены на \"вероятности\" относительно target фичи.\n",
    "\n",
    "Текстовые данные обрабатывались в отдельном пайплайне, включающем в себя:\n",
    "\n",
    "1. Токенизацию - CountVectorizer()\n",
    "2. Нормализацию со взвешиванием по tf-idf - TfidfTransformer()\n",
    "3. Предсказание классов через SGDClassifier(loss='log', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "\n",
    "На непрерывных и категориальных данных обучались два классификатора: RandomForestClassifier и CatBoostClassifier.\n",
    "Для получения предсказания на тестовых данных, предсказания всех классификаторов (SGDClassifier, RandomForestClassifier и CatBoostClassifier) работали в ансамбле, где они взвешивались и усреднялись, а среднее значение выводилось как ответ.\n",
    "\n",
    "Для оценки модели имеющийся тренировачный датасет был подразбит на test и train для тренироваки модели.\n",
    "Качество модели оценивалось площадью ROC-кривой и метрикой точности предсказаний.\n",
    "\n",
    "## Ниже приведены блоки кода лучшего из решений:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "\n",
    "class Solver:\n",
    "    \"\"\"\n",
    "        Класс принимает обучающую и тестовую выборки данных\n",
    "        и решает задачу классификации при вызове метода solve()\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_train, data_test):\n",
    "        \"\"\"\n",
    "            Вызывает методы препроцессинга данных\n",
    "        \"\"\"\n",
    "        self.data = data_train\n",
    "        self.data_test = data_test\n",
    "        self.prepare_data()\n",
    "        self.prepare_test()\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "            Препроцессинг обучающего датасета\n",
    "        \"\"\"\n",
    "        self.X_train = self.data[['lat', 'long','price']].values\n",
    "        self.y_train = self.data['sold_fast']\n",
    "        self.cat_features = ['category_id','sold_mode', 'product_type', 'payment_available', 'subcategory_id', \n",
    "                             'city', 'delivery_available', 'img_num', 'region']\n",
    "        self.cat_features_dict = self.preprocess_cat_features('sold_fast')\n",
    "        for feature in self.cat_features:\n",
    "            res = [0] * len(self.data)\n",
    "            for i, val in enumerate(self.data[feature].values):\n",
    "                res[i] = self.cat_features_dict[feature][val]\n",
    "            self.X_train = np.c_[self.X_train, np.array(res)]\n",
    "\n",
    "    def prepare_test(self):\n",
    "        \"\"\"\n",
    "            Препроцессинг тестового датасета\n",
    "        \"\"\"\n",
    "        X_test = self.data_test[['lat', 'long','price']].values #'lat', 'long', \n",
    "        for feature in self.cat_features:\n",
    "            res = [0] * len(self.data_test)\n",
    "            for i, val in enumerate(self.data_test[feature].values):\n",
    "                res[i] = self.cat_features_dict[feature].get(val, 0)\n",
    "            X_test = np.c_[X_test, np.array(res)]\n",
    "        self.X_test = X_test\n",
    "    \n",
    "    def target_encoding(self, features, targets):\n",
    "        \"\"\"\n",
    "            Инкодинг категориальных фич (унаследовано с семинара)\n",
    "        \"\"\"\n",
    "        values = defaultdict(int)\n",
    "        counts = Counter()\n",
    "        for val, target in zip(features, targets):\n",
    "            values[val] += target\n",
    "            counts[val] += 1\n",
    "\n",
    "        mean_values = dict()\n",
    "        for val in values:\n",
    "            mean_values[val] = values[val] / counts[val]\n",
    "        return mean_values\n",
    "\n",
    "    def preprocess_cat_features(self, target):\n",
    "        \"\"\"\n",
    "            Запускает инкодинг категориальных фич (унаследовано с семинара)\n",
    "        \"\"\"\n",
    "        self.cat_features_dict = dict()\n",
    "        for feature in self.cat_features:\n",
    "            self.cat_features_dict[feature] = self.target_encoding(self.data[feature].values, self.data[target].values)\n",
    "        return self.cat_features_dict\n",
    "    \n",
    "    def ensemble_proba(self):\n",
    "        \"\"\"\n",
    "            Самописный ансамбль: считает предсказания для класса [1] по всем классификаторам\n",
    "            и взвешенное среднее значение для каждого предсказания\n",
    "        \"\"\"\n",
    "        probas = []\n",
    "        df = pd.DataFrame()\n",
    "        # Random Forest Classifier\n",
    "        df['rt'] = self.rt_proba(n=100)\n",
    "        # Cat Boost Classifier\n",
    "        df['catboost'] = self.catboost_proba()\n",
    "        # Классификация текстовых фич\n",
    "        df['textCF'] = self.textCF_proba(self.data['desc_text'], self.data['sold_fast'], self.data_test['desc_text'])\n",
    "        df['nameCF'] = self.textCF_proba(self.data['name_text'], self.data['sold_fast'], self.data_test['name_text'])\n",
    "        # Переменная для анализа/дебага результатов вне класса \n",
    "        self.arr = df.values\n",
    "        return np.average(self.arr, axis = 1, weights = [0.2,0.2,0.7,0.5])\n",
    "    \n",
    "    def ensemble_score(self, y_test):\n",
    "        \"\"\"\n",
    "            Печатает точность предсказаний для каждого класса из ансамбля\n",
    "            (используется для дебага и тюнинга параметров)\n",
    "        \"\"\"\n",
    "        rt = self.rt_proba(n=10, predict = True)\n",
    "        catboost = self.catboost_proba(predict = True)\n",
    "        text = self.textCF_proba(self.data['desc_text'], self.data['sold_fast'], self.data_test['desc_text'], predict = True)\n",
    "        name = self.textCF_proba(self.data['name_text'], self.data['sold_fast'], self.data_test['name_text'], predict = True)\n",
    "        from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "        print(\"RT acc = {}\".format(accuracy_score(y_test, rt)))\n",
    "        print(\"CatBoost acc = {}\".format(accuracy_score(y_test, catboost)))\n",
    "        print(\"TextCF acc = {}\".format(accuracy_score(y_test, text)))\n",
    "        print(\"NameCF acc = {}\".format(accuracy_score(y_test, name)))\n",
    "        \n",
    "    def rt_proba(self, n=50, predict = False):\n",
    "        \"\"\"\n",
    "            Считает probability для Random Forest классификатора\n",
    "            либо предсказания, если параметр predict == True\n",
    "            Args:\n",
    "                n - int, количество деревьев в лесу\n",
    "                predict - bool, возвращать точные предсказания или вероятность\n",
    "        \"\"\"\n",
    "        rt = RandomForestClassifier(max_depth=15, n_estimators=n, random_state=43)\n",
    "        rt.fit(self.X_train, self.y_train)\n",
    "        if predict:\n",
    "            return rt.predict(self.X_test)\n",
    "        return rt.predict_proba(self.X_test)[:,1]\n",
    "    \n",
    "    def textCF_proba(self, X_train, y_train, X_test, predict = False):\n",
    "        \"\"\"\n",
    "            Считает probability для классификатора текстовых данных\n",
    "            либо предсказания, если параметр predict == True\n",
    "            Args:\n",
    "                X_train, y_train, X_test - массивы данных для классификатора\n",
    "                predict - bool, возвращать точные предсказания или вероятность\n",
    "        \"\"\"\n",
    "        textCF = TextCF()\n",
    "        textCF.fit(X_train, y_train)\n",
    "        if predict:\n",
    "            return textCF.predict(X_test)\n",
    "        text_proba = textCF.predict_proba(X_test)\n",
    "        return text_proba[:,1]\n",
    "    \n",
    "    def catboost_proba(self, predict = False):\n",
    "        \"\"\"\n",
    "            Считает probability для CatBoost классификатора\n",
    "            либо точные предсказания, если параметр predict == True\n",
    "            Args:\n",
    "                predict - bool, возвращать точные предсказания или вероятность\n",
    "        \"\"\"\n",
    "        model = CatBoostClassifier(iterations=1000,\n",
    "                          depth=6, eval_metric='AUC', od_type = 'IncToDec',\n",
    "                                  logging_level='Silent')\n",
    "    \n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        if predict:\n",
    "            return model.predict(self.X_test)\n",
    "        return model.predict_proba(self.X_test)[:,1]\n",
    "        \n",
    "    def solve(self):\n",
    "        \"\"\"\n",
    "            Решает поставленную задачу классификации\n",
    "            и записывает результат в файл для отправки\n",
    "        \"\"\"\n",
    "        self.proba = s.ensemble_proba()\n",
    "        product_id = self.data_test['product_id'].values\n",
    "        data = pd.DataFrame.from_dict({'product_id' : product_id, 'score' : self.proba})\n",
    "        data.to_csv('./to_submit', sep = ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class TextCF:\n",
    "    \"\"\"\n",
    "        Класс обёртка для пайплайна обработки и классификации текстовых данных\n",
    "        (когда-то был более полным и сложным, но в итоге остался просто обёрткой)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.text_clf = Pipeline([\n",
    "                ('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='log', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),\n",
    "                ])\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.text_clf.fit(X_train, y_train) \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        self.predicted = self.text_clf.predict(X_test)\n",
    "        return self.predicted        \n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        self.proba = self.text_clf.predict_proba(X_test)\n",
    "        return self.proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение датасетов\n",
    "data = pd.read_csv('./train.tsv', sep = '\\t')\n",
    "data_test = pd.read_csv('./test_nolabel.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестовые данные\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "train, X_test, y_test = data.iloc[:250000, :], data.iloc[250000:, :-1], data.iloc[250000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Блок для дебага классификаторов по отдельности\n",
    "s = Solver(data, data_test)\n",
    "arr = s.catboost_proba()\n",
    "print(\"ROC-AUC = {}\".format(roc_auc_score(y_test, arr)))\n",
    "# 0.6163551452254086 - # depth 6, 1000 trees - 1min 43s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jupyterlab-ext\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.6218277184031248\n",
      "Wall time: 57.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Блок для дебага ансамбля\n",
    "s = Solver(train, X_test)\n",
    "arr = s.ensemble_proba()\n",
    "print(\"ROC-AUC = {}\".format(roc_auc_score(y_test, arr)))\n",
    "# 0.627541738379946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC = 0.6218277184031248\n"
     ]
    }
   ],
   "source": [
    "# Блок для подбора весов руками\n",
    "arr = np.average(s.arr, axis = 1, weights= [0.2,0.2,0.7,0.5])\n",
    "print(\"ROC-AUC = {}\".format(roc_auc_score(y_test, arr)))\n",
    "# 0.6222343832877966 [0.2,0.2,0.7,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\envs\\jupyterlab-ext\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT acc = 0.766540614725368\n",
      "CatBoost acc = 0.7671527729781499\n",
      "TextCF acc = 0.7683869630039198\n",
      "NameCF acc = 0.7683869630039198\n",
      "Wall time: 22.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Блок тестирования точности предсказаний классов\n",
    "s = Solver(train, X_test)\n",
    "arr = s.ensemble_score(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Блок записи решения в файл для отправки\n",
    "s = Solver(data, data_test)\n",
    "s.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание альтернативных подходов/попыток\n",
    "В процессе решения задачи были выполнены попытки учесть все доступные фичи, но не все удалось включить в модель.\n",
    "Например, для фичи 'properties' было неочевидно, что лучше распарсить и учитывать даннеы как текст, либо как категории; первые попытки учесть эти данные не улучшили модель, и идея была заброшена.\n",
    "\n",
    "Фичу 'date', наоборот, было легко распарсить, после чего внедрить в датасет день и месяц добавления товара, однако результатом было переобучение модели, с которым не было возможности справиться вовремя, и фича была удалена из датасета.\n",
    "\n",
    "Набор классификаторов претерпел много изменений, в модели были перепробованы буквально все классификаторы, доступные в библиотеке scikit-learn, но лучшими оказались RandomForest и SGD. Позже к ним был добавлен CatBoost. После объединения всех класификаторов в ансамбль, подбирался вес \"голоса\" для каждого из них после любой модификации или подкрутки параметров так, чтобы основные метрики были максимальны.\n",
    "\n",
    "Многие результаты изменений моделей не сохранились, однако некоторые логи всё же остались во вспомагательных ячейках:\n",
    "Тюнинг CatBoost'а:\n",
    "- ROC: 0.6119392482947758 - depth = 2\n",
    "- ROC: 0.6155439202758909 - depth = 6\n",
    "- ROC: 0.6159188915313375 - 500 trees\n",
    "- ROC: 0.6163551452254086 - 1000 trees\n",
    "\n",
    "Ансамбль с весами и без: \n",
    "- ROC: 0.6209800843158668 [1, 1, 1, 1]\n",
    "- ROC: 0.6222343832877966 [0.2, 0.2, 0.7, 0.5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
