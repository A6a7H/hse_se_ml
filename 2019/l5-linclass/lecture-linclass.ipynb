{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/logo_hse_black.jpg\"></center>\n",
    "\n",
    "<h1><center>Data Analysis</center></h1>\n",
    "<h3><center>Andrey Shestakov (<a href=\"mailto:avshestakov@hse.ru\">avshestakov@hse.ru</a>)</center></h3>\n",
    "<hr>\n",
    "<h2><center>Regularization in linear models.</center></h2>\n",
    "<h2><center>Linear classification. Logistic Regression<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup></center></h2>\n",
    "\n",
    "\n",
    "\n",
    "<sup id=\"fn1\">1. Some materials are taken from <a href=\"http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%80%D0%B0%D0%B7%D0%BE%D0%B2_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%92.%D0%92.%D0%9A%D0%B8%D1%82%D0%BE%D0%B2%29\">machine learning course of Victor Kitov</a></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print(u'Так надо')\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Wisdom of the day\n",
    "### Overfitting = Death\n",
    "\n",
    "\n",
    "<center><img src='img/overfit-death.jpeg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's recall previous lecture\n",
    "\n",
    "* Linear regression\n",
    "    * linear dependence between target features and predictors\n",
    "\n",
    "$$f(x_{n}, \\beta) = \\hat{y}_{n} = \\beta_0 + \\beta_1x_{n}^1 + \\dots$$\n",
    "\n",
    "* Optimize Ordinary Least Squares\n",
    "* Solution can be found \n",
    "    * analytically \n",
    "    * with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "df_auto = pd.read_csv('./data/accord_sedan_training.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1177e12e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_auto.plot(x='mileage', y='price', kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price = 16762.02 -0.05*mileage\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = df_auto.loc[:,['mileage']].values\n",
    "y = df_auto.loc[:, 'price'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "print('price = {:.2f} {:.2f}*mileage'.format(model.intercept_, model.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price = 16762.02 -0.01*mileage -0.02*kilometerage\n"
     ]
    }
   ],
   "source": [
    "df_auto.loc[:, 'kilometerage'] = df_auto.loc[:,'mileage'] * 1.60934\n",
    "X = df_auto.loc[:,['mileage', 'kilometerage']].values\n",
    "y = df_auto.loc[:, 'price'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "print('price = {:.2f} {:.2f}*mileage {:.2f}*kilometerage'.format(model.intercept_, *model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization & restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Intuition\n",
    "\n",
    "<center><img src=http://www.holehouse.org/mlclass/10_Advice_for_applying_machine_learning_files/Image%20[8].png></center>\n",
    "[Andrew's Ng Machine Learning Class - Stanford]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Regularization \n",
    "\n",
    "* Insert regularizer $R(\\beta)$ for $\\beta$ to be small:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\left(x_{n}^{T}\\beta-y_{n}\\right)^{2}+\\lambda R(\\beta)\\to\\min_{\\beta}\n",
    "$$\n",
    "* $\\lambda>0$ - hyperparameter.\n",
    "* $R(\\beta)$ penalizes complexity of models.\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "R(\\beta)=||\\beta||_{1} & \\mbox{Lasso regression}\\\\\n",
    "R(\\beta)=||\\beta||_{2}^{2} & \\text{Ridge regression}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "* Not only **accuracy** matters for the solution but also **model simplicity**!\n",
    "* $\\lambda$ controls complexity of the model:$\\uparrow\\lambda\\Leftrightarrow\\text{complexity}$$\\downarrow$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Comments\n",
    "* Dependency of $\\beta$ from $\\lambda$ for ridge (A) and LASSO (B):\n",
    "<center><img src=\"img/regularization paths.png\" width=1500></center>\n",
    "\n",
    "* LASSO can be used for automatic feature selection.\n",
    "* $\\lambda$ is usually found using cross-validation on exponential grid, e.g. $[10^{-6},10^{-5},...10^{5},10^{6}]$.\n",
    "* It's always recommended to use regularization because \n",
    "    * it gives smooth control over model complexity.\n",
    "    * reduces ambiguity for multiple solutions case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=img/regul.jpg></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price = 16762.02 -0.05*mileage -0.00*kilometerage\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Lasso(alpha=1.)\n",
    "\n",
    "model.fit(X, y)\n",
    "print('price = {:.2f} {:.2f}*mileage {:.2f}*kilometerage'.format(model.intercept_, *model.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ElasticNet\n",
    "* ElasticNet:\n",
    "\n",
    "$$\n",
    "R(\\beta)=\\alpha||\\beta||_{1}+(1-\\alpha)||\\beta||_{2}^{2}\n",
    "$$\n",
    "$\\alpha\\in(0,1)$ - hyperparameter, controlling impact of each part. \n",
    "\n",
    "* If two features $x^{i}$and $x^{j}$ are equal: \n",
    "    * LASSO may take only one of them\n",
    "    * Ridge will take both with equal weight\n",
    "        * but it doesn't remove useless features\n",
    "* ElasticNet both removes useless features but gives equal weight for usefull equal features\n",
    "    * good, because feature equality may be due to chance on this particular training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Different account for different features\n",
    "\n",
    "* Traditional approach regularizes all features uniformly:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\left(x_{n}^{T}\\beta-y_{n}\\right)^{2}+\\lambda R(\\beta)\\to\\min_{w}\n",
    "$$\n",
    "* Suppose we have $K$ groups of features with indices:\n",
    "$$\n",
    "I_{1},I_{2},...I_{K}\n",
    "$$\n",
    "* We may control the impact of each group on the model by:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\left(x_{n}^{T}\\beta-y_{n}\\right)^{2}+\\lambda_{1}R(\\{\\beta_{i}|i\\in I_{1}\\})+...+\\lambda_{K}R(\\{\\beta_{i}|i\\in I_{K}\\})\\to\\min_{w}\n",
    "$$\n",
    "* $\\lambda_{1},\\lambda_{2},...\\lambda_{K}$ can be set using cross-validation\n",
    "* In practice use common regularizer but with different feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Different loss-functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Idea\n",
    "* Generalize squared to arbitrary loss:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\left(x^{T}\\beta-y_{n}\\right)^{2}\\to\\min_{\\beta}\\qquad\\Longrightarrow\\qquad\\sum_{n=1}^{N}\\mathcal{L}(x_{n}^{T}\\beta-y_{n})\\to\\min_{\\beta}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\textbf{LOSS} & \\textbf{NAME} & \\textbf{PROPERTIES}\\\\\n",
    "\\mathcal{L}(\\varepsilon)=\\varepsilon^{2} & \\text{quadratic} & \\text{differentiable}\\\\\n",
    "\\mathcal{L}(\\varepsilon)=\\left|\\varepsilon\\right| & \\text{absolute} & \\text{robust}\\\\\n",
    "\\mathcal{L}(\\varepsilon)=\\begin{cases}\n",
    "\\frac{1}{2}\\varepsilon^{2}, & \\left|\\varepsilon\\right|\\le\\delta\\\\\n",
    "\\delta\\left(\\left|\\varepsilon\\right|-\\frac{1}{2}\\delta\\right) & \\left|\\varepsilon\\right|>\\delta\n",
    "\\end{cases} & \\text{Huber} & \\text{differentiable, robust}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "* Robust means solution is robust to outliers in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"img/Loss functions.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Weighted account for observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Weighted account for observation\n",
    "\n",
    "Weighted account for observations\n",
    "$$\n",
    "\\sum_{n=1}^{N}w_{n}(x_{n}^{T}\\beta-y_{n})^{2}\n",
    "$$\n",
    "\n",
    "* Weights may be:\n",
    "* increased for incorrectly predicted objects \n",
    "    * algorithm becomes more oriented on error correction\n",
    "* decreased for incorrectly predicted objects \n",
    "    * they may be considered outliers that break our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution for weighted regression\n",
    "\n",
    "$$\n",
    "\\sum_{n=1}^{N}w_{n}\\left(x_{n}^{T}\\beta-y_{n}\\right)^{2}\\to\\min_{\\beta\\in\\mathbb{R}}\n",
    "$$\n",
    "\n",
    "Stationarity condition:\n",
    "$$\n",
    "\\sum_{n=1}^{N}w_{n}x_{n}^{d}\\left(x_{n}^{T}\\beta-y_{n}\\right)=0\n",
    "$$\n",
    "\n",
    "Define $\\{X\\}_{n,d}=x_{n}^{d}$, $W=diag\\{w_{1},...x_{N}\\}$. Then\n",
    "\n",
    "$$\n",
    "X^{T}W\\left(X\\beta-y\\right)=0\n",
    "$$\n",
    "$$\n",
    "\\beta=\\left(X^{T}WX\\right)^{-1}X^{T}Wy\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Robust regression\n",
    "\n",
    "* Initialize $w_{1}=...=w_{N}=1/N$\n",
    "\n",
    "* Repeat:\n",
    "    * estimate regression $\\widehat{y}(x)$ using observations $(x_{i},y_{i})$ with weights $w_{i}$.\n",
    "    * for each $i=1,2,...N$:\n",
    "        * calculate $\\varepsilon_{i}=\\widehat{y}(x_{i})-y_{i}$\n",
    "        * calculate $w_{i}=K\\left(\\left|\\varepsilon_{i}\\right|\\right)$ \n",
    "    * normalize weights $w_{i}=\\frac{w_{i}}{\\sum_{n=1}^{N}w_{n}}$\n",
    "\n",
    "**Comments:** $K(\\cdot)$ is some *decreasing* function, repetition may be \n",
    "* predefined number of times\n",
    "* until convergence of model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "<center><img src=\"img/data with outliers.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Classification (in general)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/512px-Svm_separating_hyperplanes_%28SVG%29.svg.png'></center>\n",
    "\n",
    "$$w_1x_1 + w_2x_2 + w_0 = w^{T}x+w_{0}=0$$\n",
    "$$ y \\in \\{-1,+1\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Analytical geometry reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reminder\n",
    "\n",
    "* $a=[a^{1},...a^{D}]^{T},\\,b=[b^{1},...b^{D}]^{T}$\n",
    "* Scalar product $\\langle a,b\\rangle=a^{T}b=\\sum_{d=1}^{D}a_{d}b_{b}$ \n",
    "* $a\\perp b$ means that $\\langle a,b\\rangle=0$\n",
    "* Norm $\\left\\lVert a\\right\\rVert =\\sqrt{\\langle a,a\\rangle}$\n",
    "* Distance $\\rho(a,b)=\\left\\lVert a-b\\right\\rVert =\\sqrt{\\langle a-b,a-b\\rangle}$\n",
    "\n",
    "\n",
    "<center><img src=\"img/projection.png\"></center>\n",
    "\n",
    "* $p=\\langle a,\\frac{b}{\\left\\lVert b\\right\\rVert }\\rangle$\n",
    "* $\\left|p\\right|=\\left|\\langle a,\\frac{b}{\\left\\lVert b\\right\\rVert }\\rangle\\right|$-\n",
    "unsigned projection length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Orthogonal vector to hyperplane\n",
    "\n",
    "### Theorem 1\n",
    "Vector $w$ is orthogonal to hyperplane $w^{T}x+w_{0}=0$\n",
    "\n",
    "**Proof:**\n",
    "Consider arbitrary $x_{A},x_{B}\\in\\{x:\\,w^{T}x+w_{0}=0\\}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "w^{T}x_{A}+w_{0}=0 \\quad \\text{   (1)}\\\\\n",
    "w^{T}x_{B}+w_{0}=0 \\quad \\text{   (2)}\n",
    "\\end{align}\n",
    "$$\n",
    "By substracting (2) from (1), obtain $w^{T}(x_{A}-x_{B})=0$,\n",
    "so $w$ is orthogonal to hyperplane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img\\Linear discriminant function 2.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Distance from point to hyperplane\n",
    "\n",
    "### Theorem 2\n",
    "Distance from point $x$ to hyperplane\n",
    "$w^{T}x+w_{0}=0$ is equal to $\\frac{w^{T}x+w_{0}}{\\left\\lVert w\\right\\rVert }$.\n",
    "\n",
    "**Proof:** Project $x$ on the hyperplane, let the projection\n",
    "be $p$ and complement $h=x-p$, orthogonal to hyperplane. Then\n",
    "$$\n",
    "x=p+h\n",
    "$$\n",
    "\n",
    "Since $p$ lies on the hyperplane, \n",
    "$$\n",
    "w^{T}p+w_{0}=0\n",
    "$$\n",
    "\n",
    "Since $h$ is orthogonal to hyperplane and according to theorem 1\n",
    "$$\n",
    "h=r\\frac{w}{\\left\\lVert w\\right\\rVert },\\,r\\in\\mathbb{R}\\text{ - distance to hyperplane}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Distance from point to hyperplane\n",
    "\n",
    "$$\n",
    "x=p+r\\frac{w}{\\left\\lVert w\\right\\rVert }\n",
    "$$\n",
    "\n",
    "After multiplication by $w$ and addition of $w_{0}$:\n",
    "$$\n",
    "w^{T}x+w_{0}=w^{T}p+w_{0}+r\\frac{w^{T}w}{\\left\\lVert w\\right\\rVert }=r\\left\\lVert w\\right\\rVert \n",
    "$$\n",
    "\n",
    "because $w^{T}p+w_{0}=0$ and $\\left\\lVert w\\right\\rVert =\\sqrt{w^{T}w}$.\n",
    "So we get, that \n",
    "$$\n",
    "r=\\frac{w^{T}x+w_{0}}{\\left\\lVert w\\right\\rVert }\n",
    "$$\n",
    "\n",
    "**Comments:**\n",
    "* From one side of hyperplane $r>0\\Leftrightarrow w^{T}x+w_{0}>0$\n",
    "* From the other side $r<0\\Leftrightarrow w^{T}x+w_{0}<0$. \n",
    "* Distance from hyperplane to origin 0 is $\\frac{w_{0}}{\\left\\lVert w\\right\\rVert }$.\n",
    "So $w_{0}$ accounts for hyperplane offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary linear classifier geometric interpretation\n",
    "\n",
    "Binary linear classifier:\n",
    "$$\n",
    "\\widehat{y}(x)= sign\\left(w^{T}x+w_{0}\\right)\n",
    "$$\n",
    "\n",
    "divides feature space by hyperplane $w^{T}x+w_{0}=0$.\n",
    "\n",
    "* Confidence of decision is proportional to distance to hyperplane $\\frac{\\left|w^{T}x+w_{0}\\right|}{\\left\\lVert w\\right\\rVert }$.\n",
    "* $w^{T}x+w_{0}$ is the confidence that class is positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider the foolowing objects\n",
    "\n",
    "| x1 | x2 |\n",
    "|---|---|\n",
    "| 0 | 1 |\n",
    "| 1 | 0 |\n",
    "| 1 | 1 |\n",
    "| 2 | 2 |\n",
    "| 2 | 3 |\n",
    "| 3 | 2 |\n",
    "\n",
    "Find class prediction if $(w_0 = -0.3 , w_1 = 0.1, w_2 = 0.1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Margin of binary linear classifier\n",
    "\n",
    "$$\n",
    "M(x,y) =y\\left(w^{T}x+w_{0}\\right)\n",
    "$$\n",
    "\n",
    "* $ y \\in \\{-1,+1\\}$\n",
    "* Margin = score, how well classifier predicted true $y$ for object $x$.\n",
    "* $M(x,y|w)>0$ <=> object $x$ is correctly classified as $y$\n",
    "    * signs of $w^{T}x+w_{0}$ and $y$ coincide\n",
    "* $|M(x,y|w)|=\\left|w^{T}x+w_{0}\\right|$ - confidence of decision\n",
    "    * proportional to distance from $x$ to hyperplane $w^{T}x+w_{0}=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Margin\n",
    "\n",
    "<center><img src=\"img/Different margin objects.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Misclassification rate optimization\n",
    "\n",
    "* Misclassification rate optimization:\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{n=1}^{N}\\mathbb{I}[M(x_{n},y_{n}|w)<0]\\to\\min_{w}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "is not recommended:\n",
    "* discontinious function, can't use numerical optimization!\n",
    "* continous margin is more informative than binary error indicator.\n",
    "\n",
    "* If we select loss function $\\mathcal{L}(M)$ such that $\\mathbb{I}[M]\\le\\mathcal{L}(M)$\n",
    "then we can optimize upper bound on misclassification rate:\n",
    "$$\n",
    "\\begin{gathered}\\begin{gathered}\\text{MISCLASSIFICATION RATE}\\end{gathered}\n",
    "=\\frac{1}{N}\\sum_{n=1}^{N}\\mathbb{I}[M(x_{n},y_{n}|w)<0]\\\\\n",
    "\\le\\frac{1}{N}\\sum_{n=1}^{N}\\mathcal{L}(M(x_{n},y_{n}|w))=L(w)\n",
    "\\end{gathered}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Weights optimization\n",
    "* Margin = score, how well classifier predicted true $y$ for object $x$.\n",
    "* Task: select such $w$ to increase $M(x_{n},y_{n}|w)$ for all $n$. \n",
    "* Formalization:\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{n=1}^{N}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)\\to\\min_{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Common loss functions\n",
    "\n",
    "<center><img src=\"img/Error indicator approximations.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Same story as in linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Same story as in linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/overfitting.jpg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $L_{1}$ regularization\n",
    "\n",
    "\n",
    "* $||w||_{1}$ regularizer should do feature selection.\n",
    "\n",
    "* Consider \n",
    "$$\n",
    "L(w)=\\sum_{n=1}^{N}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+\\lambda\\sum_{d=1}^{D}|w_{d}|\n",
    "$$\n",
    "\n",
    "* And gradient updates\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_{i}}L(w)=\\sum_{n=1}^{N}\\frac{\\partial}{\\partial w_{i}}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+\\lambda sign (w_{i})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda sign (w_{i})\\nrightarrow0\\text{ when }w_{i}\\to0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $L_{2}$ regularization\n",
    "\n",
    "$$\n",
    "L(w)=\\sum_{n=1}^{N}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+\\lambda\\sum_{d=1}^{D}w_{d}^{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_{i}}L(w)=\\sum_{n=1}^{N}\\frac{\\partial}{\\partial w_{i}}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+2\\lambda w_{i}\n",
    "$$\n",
    "$$\n",
    "2\\lambda w_{i}\\to0\\text{ when }w_{i}\\to0\n",
    "$$\n",
    "\n",
    "* Strength of regularization $\\to0$ as weights $\\to0$.\n",
    "* So $L_{2}$ regularization will not set weights exactly to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary classification\n",
    "\n",
    "* Linear classifier:\n",
    "$$\n",
    "score(\\omega_{1}|x)=w^{T}x + w_0 = g(x)\n",
    "$$\n",
    "* +relationship between score and class probability is assumed:\n",
    "$$\n",
    "p(\\omega_{1}|x)=\\sigma(w^{T}x + w_0)\n",
    "$$\n",
    "\n",
    "where $\\sigma(z)=\\frac{1}{1+e^{-z}}$ - sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def demo_sigmoid():\n",
    "    z = np.linspace(-10, 10, 100)\n",
    "\n",
    "    y = sigmoid(z)\n",
    "    plt.plot(z, y)\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$\\sigma(z)$')\n",
    "    \n",
    "def sigmoid(z): \n",
    "    return 1./(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "demo_sigmoid() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary classification: estimation\n",
    "\n",
    "* Given our assumption:\n",
    "    * $p(y=+1|x)=\\sigma(w^{T}x + w_0)$\n",
    "    * $p(y=-1|x)=1 - p(y=+1|x)$\n",
    "* we can write down Likelihood function:\n",
    "$$ \\mathcal{L}(w) = \\prod_{n=1}^N p(y_n=+1|x_n)^{\\mathbb{I}[y_n = +1]} p(y_n=-1|x_n)^{\\mathbb{I}[y_n = -1]} \\rightarrow \\max_w$$\n",
    "\n",
    "* Get rid if products:\n",
    "$$ -\\ln{\\mathcal{L}(w)} = - \\sum_{n=1}^N \\mathbb{I}[y_n = +1]\\cdot\\ln{\\sigma(w^{T}x_n+w_0))} + \\mathbb{I}[y_n = -1]\\cdot\\ln{(1-\\sigma(w^{T}x_n+w_0))} \\rightarrow \\min_w$$\n",
    "$$L(w) = -\\ln{\\mathcal{L}(w)} \\rightarrow \\min_w $$\n",
    "\n",
    "* Function $L(w)$ is also called log-loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/prob.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Another formulation\n",
    "\n",
    "Using the property $1-\\sigma(z)=\\sigma(-z)$ obtain that \n",
    "$$\n",
    "p(y=+1|x)=\\sigma(w^{T}x+w_0)\\Longrightarrow p(y=-1|x)=\\sigma(-w^{T}x - w_0)\n",
    "$$\n",
    "\n",
    "So for $y\\in\\{+1,-1\\}$\n",
    "$$\n",
    "p(y|x)=\\sigma(y(\\langle w,x\\rangle + w_0)) \n",
    "$$\n",
    "\n",
    "Therefore ML estimation can be written as:\n",
    "$$\n",
    "\\prod_{n=1}^{N}\\sigma( y_{n}(\\langle w,x_{n}\\rangle + w_0))\\to\\max_{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loss function for 2-class logistic regression\n",
    "\n",
    "For binary classification $p(y|x)=\\sigma(y(\\langle w,x\\rangle + w_0))$\n",
    "\n",
    "Estimation with ML:\n",
    "\n",
    "$$\n",
    "\\prod_{n=1}^{N}\\sigma(y_n(\\langle w,x_n\\rangle + w_0)) = \\prod_{n=1}^{N}\\sigma(y_n g(x_n)) = \\to\\max_{w}\n",
    "$$\n",
    "\n",
    "which is equivalent to \n",
    "$$\n",
    "\\sum_{n=1}^{N}\\ln(1+e^{-y_ng(x_n)})\\to\\min_{w}\n",
    "$$\n",
    "\n",
    "It follows that logistic regression is linear discriminant\n",
    "estimated with loss function $\\mathcal{L}(M)=\\ln(1+e^{-M})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/Logistic loss function.png\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiclass classification with binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiclass classification with binary classifiers\n",
    "* Task - make $C$-class classification using many binary classifiers.\n",
    "* Approaches:\n",
    "\n",
    "    * **one-versus-all**\n",
    "        * for each $c=1,2,...C$ train binary classifier on all objects and output $\\mathbb{I}[y_{n}=c]$, \n",
    "        * assign class, getting the highest score in resulting $C$ classifiers.\n",
    "\n",
    "    * **one-versus-one**\n",
    "        * for each $i,j\\in[1,2,...C],$ $i\\ne j$ learn on objects with $y_{n}\\in\\{i,j\\}$ with output $y_{n}$\n",
    "        * assign class, getting the highest score in resulting $C(C-1)/2$ classifiers.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary linear classifier\n",
    "\n",
    "* For two classes $y\\in\\{+1,-1\\}$ classifier becomes\n",
    "$$\n",
    "\\widehat{y}(x)=\\begin{cases}\n",
    "+1, & w_{+1}^{T}x+w_{+1,0}>w_{-1}^{T}x+w_{-1,0}\\\\\n",
    "-1 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "* This decision rule is equivalent to \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{y}(x) & =sign(w_{+1}^{T}x+w_{+1,0}-w_{-1}^{T}x+w_{-1,0})=\\\\\n",
    " & =sign\\left(\\left(w_{+1}^{T}-w_{-1}^{T}\\right)x+\\left(w_{+1,0}-w_{-1,0}\\right)\\right)\\\\\n",
    " & =sign\\left(w^{T}x+w_{0}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "for $w=w_{+1}-w_{-1},\\,w_{0}=w_{+1,0}-w_{-1,0}$.\n",
    "* Decision boundary $w^{T}x+w_{0}=0$ is linear.\n",
    "* Multiclass case can be solved using multiple binary classifiers with one-vs-all, one-vs-one\n",
    "    * can you imagine faulty situation with those approaches for linear classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/one versus all ambiguity.png'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/one versus one ambiguity.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear classifier for multiple classes\n",
    "\n",
    "* Classification among classes 1,2,...C. \n",
    "* Use $C$ discriminant functions $g_{c}(x)=w_{c}^{T}x+w_{c0}$\n",
    "* Decision rule:\n",
    "$$\n",
    "\\widehat{y}(x)=\\arg\\max_{c}g_{c}(x)\n",
    "$$\n",
    "* Decision boundary between classes $y=i$ and $y=j$ is linear:\n",
    "$$\n",
    "\\left(w_{i}-w_{j}\\right)^{T}x+\\left(w_{i0}-w_{j0}\\right)=0\n",
    "$$\n",
    "* Decision regions are convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Logistic regression for multiple classes\n",
    "\n",
    "Each class has a set of weights:\n",
    "$$\n",
    "\\begin{cases}\n",
    "score(\\omega_{1}|x)=w_{1}^{T}x + w_{0,1} \\\\\n",
    "score(\\omega_{2}|x)=w_{2}^{T}x + w_{0,2}\\\\\n",
    "\\cdots\\\\\n",
    "score(\\omega_{C}|x)=w_{C}^{T}x + + w_{0,C}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "+relationship between score and class probability is assumed:\n",
    "\n",
    "$$\n",
    "p(\\omega_{c}|x)=softmax(\\omega_c|W, x)=\\frac{exp(w_{c}^{T}x + w_{0,c})}{\\sum_{i}exp(w_{i}^{T}x + w_{0,i})}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Estimation with ML:**\n",
    "$$\n",
    "\\prod_{n=1}^{N}\\prod_{c=1}^{C} softmax(\\omega_c|W, x_n)^{\\mathbb{I}[y_n = w_c]}\n",
    "$$\n",
    "\n",
    "Which would lead us to cross-entropy loss function\n",
    "$$L(w) = - \\sum_{n=1}^N\\sum_{c=1}^{C} \\mathbb{I}[y_n = w_c]\\cdot\\ln{\\sigma(w_c^{T}x_n+w_{c,0}))}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "* Linear classifier - classifier with linear discriminant functions.\n",
    "* Binary linear classifier: $\\widehat{y}(x)=sign(w^{T}x+w_{0})$.\n",
    "* Perceptron, logistic, SVM - linear classifiers estimated with different loss functions.\n",
    "* Weights are selected to minimize total loss on margins.\n",
    "* Gradient descent iteratively optimizes $L(w)$ in the direction of maximum descent.\n",
    "* Stochastic gradient descent approximates $\\nabla_{w}L$ by averaging\n",
    "gradients over small subset of objects.\n",
    "* Regularization gives smooth control over model complexity.\n",
    "* $L_{1}$ regularization automatically selects features."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/1f8c4751e12938961e423759861e6e5a"
  },
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "gist": {
   "data": {
    "description": "CloudMail/hse-da-course/raw/lecture-intro/lecture-intro-v01.ipynb",
    "public": false
   },
   "id": "1f8c4751e12938961e423759861e6e5a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  },
  "widgets": {
   "state": {
    "54e80d57f79b4bfc934a2b84cf5fe7ba": {
     "views": [
      {
       "cell_index": 47
      }
     ]
    },
    "5fb17a3592634a4fba98446dacd6db43": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "6f6f6ce7b81743308b92966f225862a8": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
