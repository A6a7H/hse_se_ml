{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/logo_hse_black.jpg\"></center>\n",
    "\n",
    "<h1><center>Data Analysis</center></h1>\n",
    "<h3><center>Andrey Shestakov (<a href=\"mailto:avshestakov@hse.ru\">avshestakov@hse.ru</a>)</center></h3>\n",
    "<hr>\n",
    "<h2><center>Neural Networks 1<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup></center></h2>\n",
    "\n",
    "\n",
    "\n",
    "<sup id=\"fn1\">1. Some materials are taken from <a href=\"http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%80%D0%B0%D0%B7%D0%BE%D0%B2_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%92.%D0%92.%D0%9A%D0%B8%D1%82%D0%BE%D0%B2%29\">machine learning course of Victor Kitov</a></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's recall previous lecture\n",
    "\n",
    "## Boosting, Ensembles\n",
    "\n",
    "* Construction of multiple models to increase model quality\n",
    "    * In parallel (Bagging, Blending, Stacking, Random Forest)\n",
    "    * Sequentially (Boosting)\n",
    "* Works great!\n",
    "* Hard to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## History\n",
    "\n",
    "* Neural networks originally appeared as an attempt to model human brain\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-031e\"> <img width=400 src='img/Human brain.jpg'></th>\n",
    "    <th class=\"tg-031e\"> <img width=500 src='img/neural-network-cells.jpg'></th>\n",
    "  </tr>\n",
    "</table>\n",
    "* Human brain consists of multiple interconnected neuron cells \n",
    "\n",
    "    * cerebral cortex (the largest part) is estimated to contain 15-33 billion neurons\n",
    "    * communication is performed by sending electrical and electro-chemical signals\n",
    "    * signals are transmitted through axons - long thin parts of neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## [History](https://www.import.io/post/history-of-deep-learning/)\n",
    "\n",
    "* 1943 – The first mathematical model of a neural network (Walter Pitts and Warren McCulloch)\n",
    "* 1957 – Setting the foundation for deep neural networks (Frank Rosenblatt)\n",
    "* 1965 – The first working deep learning networks\n",
    "* 1979-80 – An ANN learns how to recognize visual patterns\n",
    "* 1982 – The creation of the Hopfield Networks\n",
    "* 1989 – Machines read handwritten digits (Yann LeCun)\n",
    "* 1997 – Long short-term memory was proposed (Jürgen Schmidhuber and Sepp Hochreiter)\n",
    "* 1998 – Gradient-based learning (Yann LeCun)\n",
    "* 2011 – Creation of AlexNet\n",
    "* 2014 – Generative Adversarial Networks (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple model of a neuron\n",
    "\n",
    "<center><img src='img/neuron-diagram.jpg'></center>\n",
    "\n",
    "* Neuron get's activated in the half-space, defined by $b+w_{1}x^{1}+w_{2}x^{2}+...+w_{D}x^{D}\\ge0$.\n",
    "* Each node is called a **neuron**\n",
    "* Each edge is associated a **weight**\n",
    "* Constant feature $b$ stands for **bias** (some times reffered as $w_0$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multilayer perceptron architecture\n",
    "\n",
    "* Hierarchically nested set of neurons.\n",
    "* Each node has its own weights.\n",
    "\n",
    "<center><img src='img/mpl.png'></center>\n",
    "\n",
    "This is structure of multilayer perceptron - acyclic directed graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/nn_zoo.jpg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Layers\n",
    "\n",
    "<center><img src='img/Neural_network_achitecture.png'></center>\n",
    "\n",
    "* Structure of neural network: \n",
    "    * 1-input layer\n",
    "    * 2-hidden layers\n",
    "    * 3-output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Continious activations\n",
    "* Pitfall of $\\mathbb{I}[]$: it causes stepwise constant outputs, weight optimization methods become inapliccable.\n",
    "* We can replace $\\mathbb{I}[w^{T}x+w_{0}\\ge0]$ with smooth activation $f(w^{T}x+w_{0})$ \n",
    "\n",
    "<center><img src='img/sigmoid approximates step function.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Typical activation functions\n",
    "\n",
    "* sigmoidal: $\\sigma(x)=\\frac{1}{1+e^{-x}}$ \n",
    "     * 1-layer neural network with sigmoidal activation is equivalent to logistic regression\n",
    "     <center><img src='img/sigmoid-activation-function.png', width=700></center>\n",
    "* hyperbolic tangent: $tangh(x)=\\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$ \n",
    "    <center><img src='img/tanh-1.png', width=700></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Typical activation functions\n",
    "     \n",
    "* ReLU: $f(x)=[x]_{+}$.\n",
    "\n",
    "<center><img src='img/relu-activation-function-1.png', width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Activation function zoo\n",
    "\n",
    "<center><img src='img/activ_functions.png', width=1200></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Definition details\n",
    "\n",
    "\n",
    "* Label each neuron with integer $j$.\n",
    "* Denote: $I_{j}$ - input to neuron $j$, $O_{j}$ - output of neuron $j$\n",
    "* Input to neuron $j$: $I_{j}=\\sum_{k\\in inc(j)}w_{kj}O_{k}+w_{0j}$,\n",
    "* Output of neuron $j$: $O_{j}=f(I_{j})$.\n",
    "\n",
    "    * $w_{0j}$ is the bias term\n",
    "    * $f(x)$ is the activation function\n",
    "    * $inc(j)$ is a set of neurons with outgoing edges incoming to neuron $j$.\n",
    "    * further we will assume that at each layer there is a vertex with constant output $O_{const}\\equiv1$, so we can simplify notation\n",
    "\n",
    "$$\n",
    "I_{j}=\\sum_{k\\in inc(j)}w_{kj}O_{k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Output Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Output generation\n",
    "\n",
    "* Forward propagation is a process of successive calculations of neuron outputs for given features.\n",
    "\n",
    "<center><img src='img/Forward propagation.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Activations at output layer\n",
    "\n",
    "* **Regression**: $f(I)=I$ (linear activation)\n",
    "* **Classification**:\n",
    "    * binary: $y\\in\\{+1,-1\\}$\n",
    "$$\n",
    "f(I)=p(y=+1|x)=\\frac{1}{1+e^{-I}}\n",
    "$$\n",
    "    * multiclass: $y\\in{1,2,...C}$\n",
    "$$\n",
    "f(I_{1},...I_{C})=p(y=j|x)=\\frac{e^{I_{j}}}{\\sum_{k=1}^{C}e^{I_{k}}},\\,j=1,2,...C\n",
    "$$\n",
    "where $I_{1},...I_{C}$ are inputs of output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Generalizations\n",
    "\n",
    "* each neuron $j$ may have custom non-linear transformation $f_{j}$\n",
    "* weights may be constrained:\n",
    "    * non-negative\n",
    "    * equal weights\n",
    "    * etc.\n",
    "* layer skips are possible\n",
    "<center><img src=\"img/Layer skipping.png\"></center>\n",
    "* Not considered here: RBF-networks, recurrent networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Number of layers selection\n",
    "\n",
    "* Number of layers usually denotes all layers except input layer (hidden layers+output layer)\n",
    "\n",
    "* **Classification**:\n",
    "\n",
    "    * single layer network selects arbitrary half-spaces\n",
    "    * 2-layer network selects arbitrary convex polyhedron (by intersection of 1-layer outputs)\n",
    "        * therefore it can approximate arbitrary convex sets\n",
    "    * 3-layer network selects (by union of 2-layer outputs) arbitrary finite sets of polyhedra\n",
    "        * therefore it can approximate almost all sets with well defined volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Number of layers selection\n",
    "\n",
    "* **Regression**:\n",
    "    * single layer can approximate arbitrary linear function\n",
    "    * 2-layer network can model indicator function of arbitrary convex polyhedron\n",
    "    * 3-layer network can uniformly approximate arbitrary continuous function (as sum weighted sum of indicators convex polyhedra)\n",
    "\n",
    "\n",
    "* **Sufficient amount of layers**\n",
    "\n",
    "<center> Any continuous function on a compact space can be uniformly approximated\n",
    "by 2-layer neural network with linear output and wide range of activation\n",
    "functions (excluding polynomial).  </center>\n",
    "\n",
    "* In practice often it is more convenient to use more layers with less total amount of neurons\n",
    "    * model becomes more interpretable and easy to fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## [TensorFlow PlayGround](https://playground.tensorflow.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural network optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Network optimization: regression\n",
    "\n",
    "* Single output:\n",
    "\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{n=1}^{N}(\\widehat{y}_{n}(x_{n})-y_{n})^{2}\\to\\min_{w}\n",
    "$$\n",
    "* K outputs\n",
    "\n",
    "$$\n",
    "\\frac{1}{NK}\\sum_{n=1}^{N}\\sum_{k=1}^{K}(\\widehat{y}_{nk}(x_{n})-y_{nk})^{2}\\to\\min_{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Network optimization: classification\n",
    "\n",
    "* Two classes ($y\\in\\{0,1\\}$):\n",
    "\n",
    "$$\n",
    "\\prod_{n=1}^{N}p(y_{n}=1|x_{n})^{y_{n}}(1-p(y_{n}=1|x_{n})){}^{1-y_{n}}\\to\\max_{w}\n",
    "$$\n",
    "\n",
    "* $C$ classes ($y_{nc}=\\mathbb{I}\\{y_{n}=c\\}$):\n",
    "\n",
    "$$\n",
    "\\prod_{n=1}^{N}\\prod_{c=1}^{C}p(y_{n}=c|x_{n})^{y_{nc}}\\to\\max_{w}\n",
    "$$\n",
    "* In practice log-likelihood  (cross-entropy) is maximized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Neural network optimization\n",
    "\n",
    "* Let $L(\\widehat{y},y)$ denote the loss function of output\n",
    "\n",
    "\n",
    "* We may optimize neural network using gradient descent:\n",
    "    \n",
    "        k=0\n",
    "        initialize randomly w_0 # small values for sigmoid and tangh\n",
    "\n",
    "        while stop criteria not met:\n",
    "            w_k+1 := w_k - alpha * grad(L(w_k))\n",
    "            k := k+1\n",
    "\n",
    "* Standardization of features makes gradient descend converge faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation algorithm\n",
    "\n",
    "<center><img src='img/backprop_spidey.jpeg', width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Idea\n",
    "\n",
    "<center><img src='img/backprop.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Definitions\n",
    "\n",
    "* Denote $w_{ij}$ as weight of edge, connecting $i$-th and $j$-th neuron\n",
    "* Define $\\delta_j = \\frac{\\partial L}{\\partial I_j} =  \\frac{\\partial L}{\\partial O_j}\\frac{\\partial O_j}{\\partial I_j}$\n",
    "* Since $L$ depends on $w_{ij}$ through the following functional relationship $L(w_{ij}) = L\\left(O_j\\left(I_j(w_{ij})\\right)\\right)$, using the chain rule we get:\n",
    "$$ \\frac{\\partial L}{\\partial w_{ij}} = \\frac{\\partial L}{\\partial I_j}\\frac{\\partial I_j}{\\partial w_{ij}} = \\delta_j O_i$$\n",
    "because $\\frac{\\partial I_j}{\\partial w_{ij}} = \\frac{\\partial}{\\partial w_{ij}} \\left(\\sum\\limits_{k\\in inc(j)} w_{kj} O_k\\right) = O_i$, where $inc(j)$ is a set of neurons with outgoing edges to neuron $j$\n",
    "* $\\frac{\\partial L}{\\partial I_j} = \\frac{\\partial L}{\\partial O_j}\\frac{\\partial O_j}{\\partial I_j} = \\frac{\\partial L}{\\partial O_j} f'(I_j) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Output layer\n",
    "\n",
    "* If neuron $j$ belongs to the output node, then error $\\frac{\\partial L}{\\partial O_j}$ is calculated directly\n",
    "* For output layer $\\delta_j$ are calculated directly:\n",
    "$$ \\delta_j= \\frac{\\partial L}{\\partial O_j}\\frac{\\partial O_j}{\\partial I_j} = \\frac{\\partial L}{\\partial O_j} f'(I_j) \\qquad (1)$$\n",
    "* Example (single point $x$ and true vector of outputs $(y_1,\\dots,y_{|OL|})$:\n",
    "    * For $L = \\frac{1}{2}\\sum\\limits_{j\\in OL}(O_j - y_j)^2$\n",
    "    $$ \\frac{\\partial L}{\\partial O_j} = O_j - y_j $$\n",
    "    * Sigmoid activation function $O_j = \\sigma(I_j)$:\n",
    "    $$ f'(I_j) = \\sigma(I_j)(1-\\sigma(I_j)) = O_j(1-O_j) $$\n",
    "    * finally\n",
    "    $$ \\delta_j = (O_j - y_j)O_j(1-O_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Inner layer\n",
    "\n",
    "* If neuron $j$ belongs to some hidden layer, denote $out(j) = \\{k_1, k_2, \\dots, k_m\\}$ the set of all neurons, receiving output of neuron $j$ as their input\n",
    "* The effect of $O_j$ on $L$ in fully absorbed by $I_{k_1},I_{k_2},\\dots,I_{k_m}$, so\n",
    "$$ \\frac{\\partial L(O_j)}{\\partial O_j} = \\frac{\\partial L(I_{k_1},I_{k_2},\\dots,I_{k_m})}{\\partial O_j} = \\sum\\limits_{k\\in out(j)} \\left( \\frac{\\partial L}{\\partial I_k} \\frac{\\partial I_k}{\\partial O_j} \\right) = \\sum\\limits_{k\\in out(j)} \\left(\\delta_k w_{jk}\\right)$$\n",
    "* So for layers other than output layer we have:\n",
    "$$ \\delta_j = \\frac{\\partial L}{\\partial I_j} =  \\frac{\\partial L}{\\partial O_j}\\frac{\\partial O_j}{\\partial I_j} = \\sum\\limits_{k\\in out(j)} \\left(\\delta_k w_{jk}\\right) f'(I_j) \\qquad (2)$$\n",
    "* Weight derivatives are calculated useing errors and outputs:\n",
    "$$ \\frac{\\partial L}{\\partial w_{ij}} = \\frac{\\partial L}{\\partial I_j}\\frac{\\partial I_j}{\\partial w_{ij}} = \\delta_jO_j \\qquad (3)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Backprop\n",
    "\n",
    "1. Forward propagate $x_n$ to the neural network, store all inputs $I_j$ and outputs $O_j$ for each neuron\n",
    "2. Calculate $\\delta_i$ for all $i \\in$ output layer using $(1)$\n",
    "3. Propagate $\\delta_i$ from final layer back layer by layer $(2)$\n",
    "4. Using calculated deltas and outputs calculate $\\frac{\\partial L}{\\partial w_{ij}}$ with $(3)$\n",
    "\n",
    "\n",
    "* Options:\n",
    "    * batch\n",
    "    * (min-batch) stochastic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/backprop2.gif'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multiple local optima problem\n",
    "\n",
    "* Optimization problem for neural nets is **non-convex**.\n",
    "* Different optima will correspond to:\n",
    "    * different starting parameter values\n",
    "    * different training samples\n",
    "\n",
    "* So we may solve task many times for different conditions and then\n",
    "    * select best model\n",
    "    * alternatively: average different obtained models to get ensemble\n",
    "\n",
    "* And/Or use some complex optimization methods\n",
    "<center><img src='img/optimization.gif'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1./(np.exp(-x) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vanishing Gradient Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x116792f90>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d292a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(-10, 10, 1000)\n",
    "gr_sigm = sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "plt.plot(x, gr_sigm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Feature scaling\n",
    "* Careful weight initialization\n",
    "* Using ReLU activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model complexity and overfitting\n",
    "\n",
    "* Constrain model directly:\n",
    "    * constrain number of neurons\n",
    "    * constrain number of layes\n",
    "    * impose constraints on weights\n",
    "* Take a flexible model\n",
    "    * early stopping (with validation set)\n",
    "    * L2 regularization\n",
    "    $$ L(w) + \\lambda\\sum_i w_i^2 $$\n",
    "* Augmentation (more used in convnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Case study: ZIP codes recognition\n",
    "\n",
    "ZIP code recognition task\n",
    "\n",
    "\n",
    "<center><img src=\"img/ZIP codes.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Neural network structures\n",
    "\n",
    "* Net1: no hidden layer\n",
    "\n",
    "* Net2: 1 hidden layer, 12 hidden units fully connected\n",
    "\n",
    "* Net3: 2 hidden layers, locally connected\n",
    "\n",
    "* Net4: 2 hidden layers, locally connected with weight sharing\n",
    "\n",
    "* Net5: 2 hidden layers, locally connected, 2 levels of weight sharing\n",
    "\n",
    "<center><img src=\"img/network structures.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<center><img src=\"img/ZIP codes - performance.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "* Advantages of neural networks:\n",
    "    * can model accurately complex non-linear relationships\n",
    "    * easily parallelizable\n",
    "\n",
    "* Disadvantages of neural networks:\n",
    "    * hardly interpretable (\"black-box\" algorithm)\n",
    "    * optimization requires skill\n",
    "        * too many parameters\n",
    "        * may converge slowly\n",
    "        * may converge to inefficient local minimum far from global one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Useful Refs\n",
    "* [Yes you should understand backprop](https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b)\n",
    "* [CS231N](http://cs231n.github.io/)\n",
    "* [Livecoding Madness!](https://www.youtube.com/watch?v=o64FV-ez6Gw)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/1f8c4751e12938961e423759861e6e5a"
  },
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "gist": {
   "data": {
    "description": "CloudMail/hse-da-course/raw/lecture-intro/lecture-intro-v01.ipynb",
    "public": false
   },
   "id": "1f8c4751e12938961e423759861e6e5a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  },
  "widgets": {
   "state": {
    "54e80d57f79b4bfc934a2b84cf5fe7ba": {
     "views": [
      {
       "cell_index": 47
      }
     ]
    },
    "5fb17a3592634a4fba98446dacd6db43": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "6f6f6ce7b81743308b92966f225862a8": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
