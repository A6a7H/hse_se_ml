{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/logo_hse_black.jpg\"></center>\n",
    "\n",
    "<h1><center>Data Analysis</center></h1>\n",
    "<h3><center>Andrey Shetakov (<a href=\"mailto:avshestakov@hse.ru\">avshestakov@hse.ru</a>)</center></h3>\n",
    "<hr>\n",
    "<h2><center>Linear classification. Logistic Regression<sup><a href=\"#fn1\" id=\"ref1\">1</a></sup></center></h2>\n",
    "\n",
    "\n",
    "\n",
    "<sup id=\"fn1\">1. Some materials are taken from <a href=\"http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5_%D0%BC%D0%B5%D1%82%D0%BE%D0%B4%D1%8B_%D1%80%D0%B0%D1%81%D0%BF%D0%BE%D0%B7%D0%BD%D0%B0%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F_%D0%BE%D0%B1%D1%80%D0%B0%D0%B7%D0%BE%D0%B2_%28%D0%BA%D1%83%D1%80%D1%81_%D0%BB%D0%B5%D0%BA%D1%86%D0%B8%D0%B9%2C_%D0%92.%D0%92.%D0%9A%D0%B8%D1%82%D0%BE%D0%B2%29\">machine learning course of Victor Kitov</a></sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn-talk')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed, FloatSlider\n",
    "except ImportError:\n",
    "    print u'Так надо'\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's recall previous lecture\n",
    "\n",
    "* Linear regression\n",
    "    * linear dependence between target features and predictors\n",
    "    * predictors themselves can be non-linear\n",
    "* Solution can be found \n",
    "    * analytically \n",
    "    * with gradient descent\n",
    "* Various loss functions options\n",
    "* Robust setting\n",
    "* Regularization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Svm_separating_hyperplanes_%28SVG%29.svg/512px-Svm_separating_hyperplanes_%28SVG%29.svg.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Analytical geometry reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Reminder\n",
    "\n",
    "* $a=[a^{1},...a^{D}]^{T},\\,b=[b^{1},...b^{D}]^{T}$\n",
    "* Scalar product $\\langle a,b\\rangle=a^{T}b=\\sum_{d=1}^{D}a_{d}b_{b}$ \n",
    "* $a\\perp b$ means that $\\langle a,b\\rangle=0$\n",
    "* Norm $\\left\\lVert a\\right\\rVert =\\sqrt{\\langle a,a\\rangle}$\n",
    "* Distance $\\rho(a,b)=\\left\\lVert a-b\\right\\rVert =\\sqrt{\\langle a-b,a-b\\rangle}$\n",
    "\n",
    "\n",
    "<center><img src=\"img/projection.png\"></center>\n",
    "\n",
    "* $p=\\langle a,\\frac{b}{\\left\\lVert b\\right\\rVert }\\rangle$\n",
    "* $\\left|p\\right|=\\left|a,\\frac{b}{\\left\\lVert b\\right\\rVert }\\right|$-\n",
    "unsigned projection length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Orthogonal vector to hyperplane\n",
    "\n",
    "### Theorem 1\n",
    "Vector $w$ is orthogonal to hyperplane $w^{T}x+w_{0}=0$\n",
    "\n",
    "**Proof:**\n",
    "Consider arbitrary $x_{A},x_{B}\\in\\{x:\\,w^{T}x+w_{0}=0\\}$:\n",
    "$$\n",
    "\\begin{align}\n",
    "w^{T}x_{A}+w_{0}=0 \\quad \\text{   (1)}\\\\\n",
    "w^{T}x_{B}+w_{0}=0 \\quad \\text{   (2)}\n",
    "\\end{align}\n",
    "$$\n",
    "By substracting (2) from (1), obtain $w^{T}(x_{A}-x_{B})=0$,\n",
    "so $w$ is orthogonal to hyperplane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Distance from point to hyperplane\n",
    "\n",
    "### Theorem 2\n",
    "Distance from point $x$ to hyperplane\n",
    "$w^{T}x+w_{0}=0$ is equal to $\\frac{w^{T}x+w_{0}}{\\left\\lVert w\\right\\rVert }$.\n",
    "\n",
    "**Proof:** Project $x$ on the hyperplane, let the projection\n",
    "be $p$ and complement $h=x-p$, orthogonal to hyperplane. Then\n",
    "$$\n",
    "x=p+h\n",
    "$$\n",
    "\n",
    "Since $p$ lies on the hyperplane, \n",
    "$$\n",
    "w^{T}p+w_{0}=0\n",
    "$$\n",
    "\n",
    "Since $h$ is orthogonal to hyperplane and according to theorem 1\n",
    "$$\n",
    "h=r\\frac{w}{\\left\\lVert w\\right\\rVert },\\,r\\in\\mathbb{R}\\text{ - distance to hyperplane}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Distance from point to hyperplane\n",
    "\n",
    "$$\n",
    "x=p+r\\frac{w}{\\left\\lVert w\\right\\rVert }\n",
    "$$\n",
    "\n",
    "After multiplication by $w$ and addition of $w_{0}$:\n",
    "$$\n",
    "w^{T}x+w_{0}=w^{T}p+w_{0}+r\\frac{w^{T}w}{\\left\\lVert w\\right\\rVert }=r\\left\\lVert w\\right\\rVert \n",
    "$$\n",
    "\n",
    "because $w^{T}p+w_{0}=0$ and $\\left\\lVert w\\right\\rVert =\\sqrt{w^{T}w}$.\n",
    "So we get, that \n",
    "$$\n",
    "r=\\frac{w^{T}x+w_{0}}{\\left\\lVert w\\right\\rVert }\n",
    "$$\n",
    "\n",
    "**Comments:**\n",
    "* From one side of hyperplane $r>0\\Leftrightarrow w^{T}x+w_{0}>0$\n",
    "* From the other side $r<0\\Leftrightarrow w^{T}x+w_{0}<0$. \n",
    "* Distance from hyperplane to origin 0 is $\\frac{w_{0}}{\\left\\lVert w\\right\\rVert }$.\n",
    "So $w_{0}$ accounts for hyperplane offset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img\\Linear discriminant function 2.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary linear classifier geometric interpretation\n",
    "\n",
    "Binary linear classifier:\n",
    "$$\n",
    "\\widehat{y}(x)= sign\\left(w^{T}x+w_{0}\\right)\n",
    "$$\n",
    "\n",
    "divides feature space by hyperplane $w^{T}x+w_{0}=0$.\n",
    "\n",
    "* Confidence of decision is proportional to distance to hyperplane $\\frac{\\left|w^{T}x+w_{0}\\right|}{\\left\\lVert w\\right\\rVert }$.\n",
    "* $w^{T}x+w_{0}$ is the confidence that class is positive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multiclass classification with binary classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiclass classification with binary classifiers\n",
    "* Task - make $C$-class classification using many binary classifiers.\n",
    "* Approaches:\n",
    "\n",
    "    * **one-versus-all**\n",
    "        * for each $c=1,2,...C$ train binary classifier on all objects and output $\\mathbb{I}[y_{n}=c]$, \n",
    "        * assign class, getting the highest score in resulting $C$ classifiers.\n",
    "\n",
    "    * **one-versus-one**\n",
    "        * for each $i,j\\in[1,2,...C],$ $i\\ne j$ learn on objects with $y_{n}\\in\\{i,j\\}$ with output $y_{n}$\n",
    "        * assign class, getting the highest score in resulting $C(C-1)/2$ classifiers.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary linear classifier\n",
    "\n",
    "* For two classes $y\\in\\{+1,-1\\}$ classifier becomes\n",
    "$$\n",
    "\\widehat{y}(x)=\\begin{cases}\n",
    "+1, & w_{+1}^{T}x+w_{+1,0}>w_{-1}^{T}x+w_{-1,0}\\\\\n",
    "-1 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "* This decision rule is equivalent to \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\widehat{y}(x) & =sign(w_{+1}^{T}x+w_{+1,0}-w_{-1}^{T}x+w_{-1,0})=\\\\\n",
    " & =sign\\left(\\left(w_{+1}^{T}-w_{-1}^{T}\\right)x+\\left(w_{+1,0}-w_{-1,0}\\right)\\right)\\\\\n",
    " & =sign\\left(w^{T}x+w_{0}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "for $w=w_{+1}-w_{-1},\\,w_{0}=w_{+1,0}-w_{-1,0}$.\n",
    "* Decision boundary $w^{T}x+w_{0}=0$ is linear.\n",
    "* Multiclass case can be solved using multiple binary classifiers with one-vs-all, one-vs-one\n",
    "    * can you imagine faulty situation with those approaches for linear classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/one versus all ambiguity.png'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/one versus one ambiguity.png'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Linear classifier\n",
    "\n",
    "* Classification among classes 1,2,...C. \n",
    "* Use $C$ discriminant functions $g_{c}(x)=w_{c}^{T}x+w_{c0}$\n",
    "* Decision rule:\n",
    "$$\n",
    "\\widehat{y}(x)=\\arg\\max_{c}g_{c}(x)\n",
    "$$\n",
    "* Decision boundary between classes $y=i$ and $y=j$ is linear:\n",
    "$$\n",
    "\\left(w_{i}-w_{j}\\right)^{T}x+\\left(w_{i0}-w_{j0}\\right)=0\n",
    "$$\n",
    "* Decision regions are convex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Margin of binary linear classifier\n",
    "\n",
    "$$\n",
    "M(x,y) =y\\left(w^{T}x+w_{0}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "* Margin = score, how well classifier predicted true $y$ for object $x$.\n",
    "* $M(x,y|w)>0$ <=> object $x$ is correctly classified as $y$\n",
    "    * signs of $w^{T}x+w_{0}$ and $y$ coincide\n",
    "* $|M(x,y|w)|=\\left|w^{T}x+w_{0}\\right|$ - confidence of decision\n",
    "    * proportional to distance from $x$ to hyperplane $w^{T}x+w_{0}=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Margin\n",
    "\n",
    "<center><img src=\"img/Different margin objects.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Weights optimization\n",
    "* Margin = score, how well classifier predicted true $y$ for object $x$.\n",
    "* Task: select such $w$ to increase $M(x_{n},y_{n}|w)$ for all $n$. \n",
    "* Formalization:\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{n=1}^{N}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)\\to\\min_{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Misclassification rate optimization\n",
    "\n",
    "* Misclassification rate optimization:\n",
    "$$\n",
    "\\frac{1}{N}\\sum_{n=1}^{N}\\mathbb{I}[M(x_{n},y_{n}|w)<0]\\to\\min_{w}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "is not recommended:\n",
    "* discontinious function, can't use numerical optimization!\n",
    "* continous margin is more informative than binary error indicator.\\pause\n",
    "\n",
    "* If we select loss function $\\mathcal{L}(M)$ such that $\\mathbb{I}[M]\\le\\mathcal{L}(M)$\n",
    "then we can optimize upper bound on misclassification rate:\n",
    "$$\n",
    "\\begin{gathered}\\begin{gathered}\\text{MISCLASSIFICATION RATE}\\end{gathered}\n",
    "=\\frac{1}{N}\\sum_{n=1}^{N}\\mathbb{I}[M(x_{n},y_{n}|w)<0]\\\\\n",
    "\\le\\frac{1}{N}\\sum_{n=1}^{N}\\mathcal{L}(M(x_{n},y_{n}|w))=L(w)\n",
    "\\end{gathered}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Common loss functions\n",
    "\n",
    "<center><img src=\"img/Error indicator approximations.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Same story as in linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Same story as in linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/overfitting.jpg'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Regularization\n",
    "\n",
    "* Insert additional requirement for regularizer $R(\\beta)$ to be small:\n",
    "$$\n",
    "\\sum_{n=1}^{N}\\mathcal{L}\\left(M(x_{n},y_{n}|w\\right)+\\lambda R(\\beta)\\to\\min_{\\beta}\n",
    "$$\n",
    "* $\\lambda>0$ - hyperparameter.\n",
    "* $R(\\beta)$ penalizes complexity of models.\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "R(\\beta)=||\\beta||_{1} & L_{1}\\text{ regularization}\\\\\n",
    "R(\\beta)=||\\beta||_{2}^{2} & L_{2}\\text{ regularization}\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $L_{1}$ regularization\n",
    "\n",
    "\n",
    "* $||w||_{1}$ regularizer should do feature selection.\n",
    "\n",
    "* Consider \n",
    "$$\n",
    "L(w)=\\sum_{n=1}^{N}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+\\lambda\\sum_{d=1}^{D}|w_{d}|\n",
    "$$\n",
    "\n",
    "* And gradient updates\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_{i}}L(w)=\\sum_{n=1}^{N}\\frac{\\partial}{\\partial w_{i}}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+\\lambda sign (w_{i})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda sign (w_{i})\\nrightarrow0\\text{ when }w_{i}\\to0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## $L_{2}$ regularization\n",
    "\n",
    "$$\n",
    "L(w)=\\sum_{n=1}^{N}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+\\lambda\\sum_{d=1}^{D}w_{d}^{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial w_{i}}L(w)=\\sum_{n=1}^{N}\\frac{\\partial}{\\partial w_{i}}\\mathcal{L}\\left(M(x_{n},y_{n}|w)\\right)+2\\lambda w_{i}\n",
    "$$\n",
    "$$\n",
    "2\\lambda w_{i}\\to0\\text{ when }w_{i}\\to0\n",
    "$$\n",
    "\n",
    "* Strength of regularization $\\to0$ as weights $\\to0$.\n",
    "* So $L_{2}$ regularization will not set weights exactly to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the foolowing objects\n",
    "\n",
    "| x1 | x2 |\n",
    "|---|---|\n",
    "| 0 | 1 |\n",
    "| 1 | 0 |\n",
    "| 1 | 1 |\n",
    "| 2 | 2 |\n",
    "| 2 | 3 |\n",
    "| 3 | 2 |\n",
    "\n",
    "Find class prediction if $(w_0 = -0.3 , w_1 = 0.1, w_2 = 0.1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary classification\n",
    "\n",
    "* Linear classifier:\n",
    "$$\n",
    "score(\\omega_{1}|x)=w^{T}x + w_0 = g(x)\n",
    "$$\n",
    "* +relationship between score and class probability is assumed:\n",
    "$$\n",
    "p(\\omega_{1}|x)=\\sigma(w^{T}x + w_0)\n",
    "$$\n",
    "\n",
    "where $\\sigma(z)=\\frac{1}{1+e^{-z}}$ - sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def demo_sigmoid():\n",
    "    z = np.linspace(-10, 10, 100)\n",
    "\n",
    "    y = sigmoid(z)\n",
    "    plt.plot(z, y)\n",
    "    plt.xlabel('$z$')\n",
    "    plt.ylabel('$\\sigma(z)$')\n",
    "    \n",
    "def sigmoid(z): \n",
    "    return 1./(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAHwCAYAAAAByRFLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109049050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "demo_sigmoid() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Binary classification: estimation\n",
    "\n",
    "Using the property $1-\\sigma(z)=\\sigma(-z)$ obtain that \n",
    "$$\n",
    "p(y=+1|x)=\\sigma(w^{T}x+w_0)\\Longrightarrow p(y=-1|x)=\\sigma(-w^{T}x - w_0)\n",
    "$$\n",
    "\n",
    "So for $y\\in\\{+1,-1\\}$\n",
    "$$\n",
    "p(y|x)=\\sigma(y(\\langle w,x\\rangle + w_0)) \n",
    "$$\n",
    "\n",
    "Therefore ML estimation can be written as:\n",
    "$$\n",
    "\\prod_{i=1}^{N}\\sigma( y_{i}(\\langle w,x_{i}\\rangle + w_0))\\to\\max_{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Loss function for 2-class logistic regression\n",
    "\n",
    "For binary classification $p(y|x)=\\sigma(y(\\langle w,x\\rangle + w_0))$\n",
    "\n",
    "Estimation with ML:\n",
    "\n",
    "$$\n",
    "\\prod_{i=1}^{n}\\sigma(y_{i}(\\langle w,x_{i}\\rangle + w_0)) = \\prod_{i=1}^{n}\\sigma(y_{i}g(x_{i})) = \\to\\max_{w}\n",
    "$$\n",
    "\n",
    "which is equivalent to \n",
    "$$\n",
    "\\sum_{i}^{n}\\ln(1+e^{-y_{i}g(x_{i})})\\to\\min_{w}\n",
    "$$\n",
    "\n",
    "It follows that logistic regression is linear discriminant\n",
    "estimated with loss function $\\mathcal{L}(M)=\\ln(1+e^{-M})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"img/Logistic loss function.png\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Another formulation\n",
    "Lets present Likelihood function in another form\n",
    "$$ \\mathcal{L}(w) = \\prod_i^n p(y=+1|x)^{[y^{(i)} = +1]} p(y=-1|x)^{[y^{(i)} = -1]} \\rightarrow \\max_w$$\n",
    "$$ -\\ln{\\mathcal{L}(w)} = - \\sum_i^n [y^{(i)} = +1]\\cdot\\ln{\\sigma(w^{T}x+w_0))} + {[y^{(i)} = -1]}\\cdot\\ln{(1-\\sigma(w^{T}x+w_0))} \\rightarrow \\min_w$$\n",
    "$$L(w) = \\log{\\mathcal{L}(w)} \\rightarrow \\min_w $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='img/prob.png' width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multiple classes\n",
    "\n",
    "Multiple class classification:\n",
    "$$\n",
    "\\begin{cases}\n",
    "score(\\omega_{1}|x)=w_{1}^{T}x + w_{0,1} \\\\\n",
    "score(\\omega_{2}|x)=w_{2}^{T}x + w_{0,2}\\\\\n",
    "\\cdots\\\\\n",
    "score(\\omega_{C}|x)=w_{C}^{T}x + + w_{0,C}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "+relationship between score and class probability is assumed:\n",
    "\n",
    "$$\n",
    "p(\\omega_{c}|x)=softmax(\\omega_c|W, x)=\\frac{exp(w_{c}^{T}x + w_{0,c})}{\\sum_{i}exp(w_{i}^{T}x + w_{0,i})}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Estimation with ML:**\n",
    "$$\n",
    "\\prod_{n=1}^{N}\\prod_{c=1}^{C} softmax(\\omega_c|W, x_i)^{[y_i = w_c]}\n",
    "$$\n",
    "\n",
    "Which would lead us to cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "* Linear classifier - classifier with linear discriminant functions.\n",
    "* Binary linear classifier: $\\widehat{y}(x)=sign(w^{T}x+w_{0})$.\n",
    "* Perceptron, logistic, SVM - linear classifiers estimated with different loss functions.\n",
    "* Weights are selected to minimize total loss on margins.\n",
    "* Gradient descent iteratively optimizes $L(w)$ in the direction of maximum descent.\n",
    "* Stochastic gradient descent approximates $\\nabla_{w}L$ by averaging\n",
    "gradients over small subset of objects.\n",
    "* Regularization gives smooth control over model complexity.\n",
    "* $L_{1}$ regularization automatically selects features."
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/1f8c4751e12938961e423759861e6e5a"
  },
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "gist": {
   "data": {
    "description": "CloudMail/hse-da-course/raw/lecture-intro/lecture-intro-v01.ipynb",
    "public": false
   },
   "id": "1f8c4751e12938961e423759861e6e5a"
  },
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "livereveal": {
   "theme": "serif",
   "transition": "concave",
   "width": "1024px"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "513px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "32px",
   "left": "9px",
   "right": "1379px",
   "top": "33px",
   "width": "212px"
  },
  "widgets": {
   "state": {
    "54e80d57f79b4bfc934a2b84cf5fe7ba": {
     "views": [
      {
       "cell_index": 47
      }
     ]
    },
    "5fb17a3592634a4fba98446dacd6db43": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "6f6f6ce7b81743308b92966f225862a8": {
     "views": [
      {
       "cell_index": 34
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
