{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/logo_hse_black.jpg\"></center>\n",
    "\n",
    "<h1><center>Data Analysis</center></h1>\n",
    "<h2><center>Seminar: SVM</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function `select_model` should take train set and output fitted svm model with best hyperparameters.\n",
    "\n",
    "You should iterate over the following hyperparameters:\n",
    "- kernel type (linear, RBF, polynomial with different degrees)\n",
    "- different $C$ ($0.1, 1, 10, 100, 1000, 10000$)\n",
    "\n",
    "Use 10-fold cross-validation and `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_model(x, y):\n",
    "    \"\"\"\n",
    "    Implement some model selection strategy here:\n",
    "    seek through different kernels and parameters.\n",
    "\n",
    "    Use a validation scheme to select the best model\n",
    "    \n",
    "    Quality metric: accuracy\n",
    "\n",
    "    Returns:\n",
    "        SVM classifier implemented by sklearn SVC class.\n",
    "    \"\"\"\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "\n",
    "    model = SVC()\n",
    "    \n",
    "    model.fit(x, y)\n",
    "    \n",
    "    best_model = model\n",
    "    yhat = best_model.predict(x)\n",
    "    best_accuracy = accuracy_score(y, yhat)\n",
    "\n",
    "    print \"Best model %s, with accuracy %f\" % (best_model, best_accuracy)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_data_set(x, y, description=''):\n",
    "    print \"Plotting data set points\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "\n",
    "    colors = np.array(['r', 'b'])[y]\n",
    "    plt.title(description, fontsize='small')\n",
    "    plt.scatter(x[:, 0], x[:, 1], marker='o', c=colors, s=50)\n",
    "    \n",
    "def plot_decision_region(x1_min, x2_min, x1_max, x2_max, clf, n_points=1000):\n",
    "    print \"Plotting decision region\"\n",
    "    x1, x2 = np.meshgrid(np.linspace(x1_min, x1_max, n_points), np.linspace(x2_min, x2_max, n_points))\n",
    "    z = clf.decision_function(np.c_[x1.ravel(), x2.ravel()]).reshape(x1.shape)\n",
    "\n",
    "    plt.contour(x1, x2, z, levels=[0.0], linestyles='solid', linewidths=2.0)\n",
    "    plt.contour(x1, x2, z, levels=[-1.0, 1.0], linestyles='dashed', linewidths=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_linear(size=100, k=1.1, b=0.0, nl=0.1):\n",
    "    print \"Generating 'Linearly-separated' data set\"\n",
    "\n",
    "    x = np.random.random((size, 2))\n",
    "    y = np.zeros(size, dtype=int)\n",
    "    noise = np.random.randn(size) * nl\n",
    "    y[x[:, 1] - (k * x[:, 0] + b) > noise] = 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = generate_linear()\n",
    "clf = select_model(x, y)\n",
    "plot_data_set(x, y)\n",
    "plot_decision_region(x[:, 0].min(), x[:, 1].min(), x[:, 0].max(), x[:, 1].max(), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_concentric(size=100, r1=1.0, r2=2.0, sigma=0.3):\n",
    "    print \"Generating 'Concentric circles' data set\"\n",
    "    x = np.zeros((size, 2))\n",
    "    x[:size/2, 0] = sigma * np.random.randn(size/2) + r1\n",
    "    x[size/2:, 0] = sigma * np.random.randn(size/2) + r2\n",
    "    x[:, 1] = (np.random.random(size) - 0.5) * 2 * np.pi\n",
    "    y = np.hstack([np.zeros(size/2, dtype=int), np.ones(size/2, dtype=int)])\n",
    "\n",
    "    z = np.zeros((size, 2))\n",
    "    z[:, 0] = x[:, 0] * np.cos(x[:, 1])\n",
    "    z[:, 1] = x[:, 0] * np.sin(x[:, 1])\n",
    "\n",
    "    return z, y\n",
    "\n",
    "x, y = generate_concentric()\n",
    "clf = select_model(x, y)\n",
    "plot_data_set(x, y)\n",
    "plot_decision_region(x[:, 0].min(), x[:, 1].min(), x[:, 0].max(), x[:, 1].max(), clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sin(size=200):\n",
    "    print \"Generating 'Sinus-separated' data set\"\n",
    "\n",
    "    x = np.random.random((size, 2))\n",
    "    x[:, 0] = x[:, 0] * 4 * np.pi\n",
    "    x[:, 1] = (x[:, 1] - 0.5) * 2\n",
    "    y = np.zeros(size, dtype=int)\n",
    "    y[x[:, 1] > np.sin(x[:, 0])] = 1\n",
    "\n",
    "    return x, y\n",
    "\n",
    "x, y = generate_sin()\n",
    "clf = select_model(x, y)\n",
    "plot_data_set(x, y)\n",
    "plot_decision_region(x[:, 0].min(), x[:, 1].min(), x[:, 0].max(), x[:, 1].max(), clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider *titanium.csv*<br/>\n",
    "\n",
    "We should predict 'y' with 'x'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data (only `x` column) and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider 3 kernels\n",
    "* Linear\n",
    "* Polynomial (degree = 3, gamma = 6, coef0 = 1)\n",
    "* RBF (gamma = 6, coef0 = 1)\n",
    "\n",
    "Set `epsilon=0.01`\n",
    "\n",
    "For each kernel:\n",
    "1. For each `C` in `np.logspace(-2, 2, 10)` find and plot mean absolute error of a model\n",
    "2. For best $ะก$ at each kernel plot initial dataset with SVM predictions\n",
    "\n",
    "Everything is performent on training set (no splitting and CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to try to determinte the language of the word and use custom kernel for that task\n",
    "\n",
    "We are going to have to texts - some first sentences of War and Peace in spanish and english. Lets say we don't know what ngramms are and consider [edit distance](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D1%81%D1%82%D0%BE%D1%8F%D0%BD%D0%B8%D0%B5_%D0%9B%D0%B5%D0%B2%D0%B5%D0%BD%D1%88%D1%82%D0%B5%D0%B9%D0%BD%D0%B0) between strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edit_dist(string_1, string_2):\n",
    "    \"\"\"\n",
    "    Calculates the Levenshtein distance between two strings.\n",
    "    \"\"\"\n",
    "    len_1 = len(string_1) + 1\n",
    "    len_2 = len(string_2) + 1\n",
    "\n",
    "    d = [0] * (len_1 * len_2)\n",
    "\n",
    "    for i in range(len_1):\n",
    "        d[i] = i\n",
    "    for j in range(len_2):\n",
    "        d[j * len_1] = j\n",
    "\n",
    "    for j in range(1, len_2):\n",
    "        for i in range(1, len_1):\n",
    "            if string_1[i - 1] == string_2[j - 1]:\n",
    "                d[i + j * len_1] = d[i - 1 + (j - 1) * len_1]\n",
    "            else:\n",
    "                d[i + j * len_1] = min(\n",
    "                   d[i - 1 + j * len_1] + 1,        # deletion\n",
    "                   d[i + (j - 1) * len_1] + 1,      # insertion\n",
    "                   d[i - 1 + (j - 1) * len_1] + 1,  # substitution\n",
    "                )\n",
    "\n",
    "    return d[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edit_dist('kitten', 'sitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data\n",
    "Load *war_and_peace_es.txt* and *war_and_peace_en.txt*.<br/> \n",
    "Make a single dataframe with a column for word and class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some data preparations\n",
    "\n",
    "One issue with custom kernels is that `sklean.SVC` requires them to accept only numbers.<br/>\n",
    "In our case that should be the indices of words: for instance, instead of strings ['treat', 'celebrit', 'prince', ...] custom kernel should take indices [9209, 11145, 7735, ...].\n",
    "\n",
    "Before that:\n",
    "1. Set `RND_SEED`\n",
    "2. Shuffle and reindex dataframe with words (ะธัะฟะพะปัะทัะนัะต ะผะตัะพะดั df.sample() ะธ df.reset_index())\n",
    "3. Limit dataframe up to 1000 words\n",
    "4. Split to train and test with 60/40\n",
    "\n",
    "In the end matrices X_train, X_test should contain **indices** of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND_SEED = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Some guidence [here](http://stackoverflow.com/questions/26962159/how-to-use-a-custom-svm-kernel).\n",
    "\n",
    "TD;DR:<br/>\n",
    "Custom kernel should accept two matrices: $U$ ะธ $V$ with features (during training they both are for training set, during prediction - one for train and one for test set).\n",
    "\n",
    "As a result it should return a matrix $G_{ij} = K(U_i, V_j)$.\n",
    "\n",
    "We should:\n",
    "1. Implement function *string_kernel(U, V)*\n",
    "2. Visualize it matrix (plt.imshow())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def string_kernel(U, V):\n",
    "    #Your Code Here\n",
    "\n",
    "G = string_kernel(X_train, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality estimation\n",
    "\n",
    "Check quality measure with different `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
