{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis for Software Engineers\n",
    "\n",
    "## Practical Assignment 2\n",
    "## Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr\\>\n",
    "**General Information**\n",
    "\n",
    "**Due date:** 17 February 2018, 23:59 <br\\>\n",
    "**Submission link:** [here](https://www.dropbox.com/request/HLKn1AOAohYOCgu6NG6i)\n",
    "\n",
    "Add your name to this notebook's title<br\\>\n",
    "<hr\\>\n",
    "\n",
    "Take in to account that some tasks may not have rigorous and comprehensive solution.<br\\>\n",
    "Support your code with comments and illustation if needed. The more conclusions, derivations and explanations you provide - the better. <br\\>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree implementation (4 points + 1 bonus)\n",
    "\n",
    "To complete this task you have to implement decision tree algorithm for classification task. Key features:\n",
    "* Sklearn estimator interface (`fit`, `predict` and `predict_proba` methods)\n",
    "* During threshold seach implement exastive and histogram-based approaches\n",
    "    * In exastive approach all intermediate values of features are considered as candidates for threshold\n",
    "    * In histogram-based approach you consider only borders of histogram, say, with 20 bins (see `numpy.percentile()`)\n",
    "* Structural hyperparameters: `max_depth` and `min_samples_leaf`. You can implement more if you wish\n",
    "* Impurity functions: Gini, Classification error, Entropy\n",
    "* Tree visualization: method to convert your tree to .dot format for graphvis and plot it\n",
    "* Featuer importances (1 bonus point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, id, samples, prediction, \n",
    "                 impurity, parent_node=None):\n",
    "        if parent_node is None:\n",
    "            self.depth = 0\n",
    "        else:\n",
    "            self.depth = parent_node.depth + 1\n",
    "            \n",
    "        self.id = id\n",
    "        self.parent_node = parent_node\n",
    "        self.samples = np.array(samples)\n",
    "        self.prediction = prediction\n",
    "        self.impurity = impurity\n",
    "        self.feature_name = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "\n",
    "class MyDecisionTree(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(impurity='gini', max_depth=None, min_samples_leaf=1, splitter='exact'):\n",
    "        self.impurity = impurity        \n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.splitter = splitter\n",
    "        self.nodes = []\n",
    "\n",
    "        # Fill in\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Fill in\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Fill in\n",
    "        \n",
    "    def predict_proba(self, X)\n",
    "        # Fill in\n",
    "\n",
    "    def plot_tree(self, filename='tree.dot'):\n",
    "        # Fill in\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking on simple datasets (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check your decision tree on some basic datasets.\n",
    "\n",
    "For each dataset output tree visualization and decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "RND_SEED = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circles():\n",
    "    return make_circles(n_samples=1000, shuffle=True, noise=0.1, factor=0.2, random_state=RND_SEED)\n",
    "\n",
    "\n",
    "def get_moons():\n",
    "    return make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=RND_SEED)\n",
    "\n",
    "\n",
    "def get_blobs():\n",
    "    return make_blobs(n_samples=1000, n_features=2, centers=3, shuffle=True, cluster_std=0.9, random_state=RND_SEED)\n",
    "\n",
    "\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    fig = plt.figure()\n",
    "    X1min, X2min = X.min(axis=0)\n",
    "    X1max, X2max = X.max(axis=0)\n",
    "    x1, x2 = np.meshgrid(np.linspace(X1min, X1max, 500),\n",
    "                         np.linspace(X2min, X2max, 500))\n",
    "    ypred = model.predict(np.c_[x1.ravel(), x2.ravel()])\n",
    "    ypred = ypred.reshape(x1.shape)\n",
    "    \n",
    "    plt.contourf(x1, x2, ypred, alpha=.4)\n",
    "    plt.scatter(X[:,0], X[:,1], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_circles()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDecisionTree(someparams).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_moons()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MyDecisionTree(someparams).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_blobs()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyDecisionTree(someparams).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.plot_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training speed calculation (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `make_classification` function to generate datasets. Run the following experiments on trees with maximum depth:\n",
    "* Run decision tree algorithm for datasets with $N \\in \\{100, 500, 1000, 2000, 5000, 10000, 30000\\}$ and $D=20$ features. Plot time (in sec) for each $N$\n",
    "    * Compare exact and histogram theshold estimation\n",
    "    \n",
    "    \n",
    "* Run decision tree algorithm for datasets with $N=1000$ and $D \\in \\{5, 10, 20, 50, 100, 200, 500\\}$ features. Plot time (in sec) for each $D$\n",
    "    * Compare exact and histogram theshold estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=RND_SEED)\n",
    "\n",
    "t1 = time()\n",
    "model = MyDecisionTree(splitter='exact').fit(X, y)\n",
    "t2 = time()\n",
    "\n",
    "print('{} seconds passed'.format(t2 - t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Dataset (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "In this part of the task you should predict whether income of a person exceeds 50K.\n",
    "1. Load the data from `adult_data_small.csv`\n",
    "2. Prepare the data for a classification algorithm: use one-hot encoding for categorical features, encode binary features and target feature \"salary\".\n",
    "3. Split the data into random train and test subsets in proportion 70:30. Don't forget to use random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc_dataset(df_input):\n",
    "    df_preproc = df_input.copy()\n",
    "    \n",
    "    # Fill in\n",
    "    \n",
    "    return df_preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be the accuracy of the algorithm, which predicts only majority class on test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use training set for hyperparameter selection\n",
    "* You should use implemented algorithm\n",
    "* Perform grid-search of `max_depth` and `min_samples_leaf` with Stratified 5-Fold cross-validation. Don't forget to use `random_state`!\n",
    "* Use \"accuracy\" as main quality measure\n",
    "* Pick the best hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Which features turned out to be the most important?\n",
    "    * If you did not implement feature importance try looking at tree visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the best model to test set and calculate accuracy\n",
    "* Compare it with accuracy during cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "235px",
    "width": "253px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
