{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.neighbors import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to modify `KNNClassifier` class from your practice in class. The `KNNClassifier` class with empty methods is provided below. Please, modify it to do all tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNClassifier(object):\n",
    "    \n",
    "    def __init__(self, max_dist=1., n_neighbors=3, use_kd_tree=False, use_weights=False):\n",
    "        \"\"\"\n",
    "        This is a constructor of the class. \n",
    "        Here you can define parameters (max_dist) of the class and \n",
    "        attributes, that are visible within all methods of the class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        max_dist : float\n",
    "            Maximum distance between an object and its neighbors.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Make this parameter visible in all methods of the class\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.max_dist = max_dist\n",
    "        self.use_kd_tree = use_kd_tree\n",
    "        self.use_weights = use_weights\n",
    "                \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This method trains the KNN classifier. \n",
    "        Actualy, the KNN classifier has no training procedure.\n",
    "        It just remembers data (X, y) that will be used for predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        y : numpy.array, shape = (n_objects)\n",
    "            1D array with the object labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs labels prediction for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted : numpy.array, shape = (n_objects)\n",
    "            1D array with predicted labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        y_predicted = []\n",
    "        self.labels_count = []\n",
    "        if self.max_dist:\n",
    "            for x_sample in X:\n",
    "                if self.use_kd_tree:\n",
    "                    index_nei = cKDTree(self.X, leafsize=30).query_ball_point(x_sample, self.max_dist)\n",
    "                    classes = self.y[index_nei]\n",
    "                    objects = self.X[index_nei]\n",
    "                    weight = np.array([1] * len(classes))\n",
    "                    if self.use_weights:\n",
    "                        distance = np.apply_along_axis(lambda dataset_row: \n",
    "                                        self._distance_between_dataset(dataset_row, x_sample), 1, objects)\n",
    "                        weight = distance[np.where(distance < self.max_dist)]**(-1)\n",
    "                    self.result = {}\n",
    "                    for label in np.unique(self.y):\n",
    "                        self.result[label] = weight[classes == label].sum()\n",
    "                    self.labels_count.append(self.result)\n",
    "                    y_predicted.append(Counter(self.result).most_common()[0][0])\n",
    "                else:\n",
    "                    distance = np.apply_along_axis(lambda dataset_row: \n",
    "                                        self._distance_between_dataset(dataset_row, x_sample), 1, self.X)\n",
    "                    classes = self.y[np.where(distance < self.max_dist)]\n",
    "                    weight = np.array([1] * len(np.where(distance < self.max_dist)[0]))\n",
    "                    if self.use_weights:\n",
    "                        weight = distance[np.where(distance < self.max_dist)]**(-1)\n",
    "                    self.result = {}\n",
    "                    for label in np.unique(self.y):\n",
    "                        self.result[label] = weight[classes == label].sum()\n",
    "                    self.labels_count.append(self.result)\n",
    "                    y_predicted.append(Counter(self.result).most_common()[0][0])\n",
    "\n",
    "        else:\n",
    "            self.n_neighbors = 3 if self.n_neighbors is None else self.n_neighbors\n",
    "            for x_sample in X:\n",
    "                if self.use_kd_tree:\n",
    "                        index_nei = cKDTree(self.X, leafsize=30).query(x_sample, self.n_neighbors)[1]\n",
    "                        classes = self.y[index_nei]\n",
    "                        objects = self.X[index_nei]\n",
    "                        weight = np.array([1] * len(classes))\n",
    "                        if self.use_weights:\n",
    "                            distance = np.apply_along_axis(lambda dataset_row: \n",
    "                                            self._distance_between_dataset(dataset_row, x_sample), 1, objects)\n",
    "                            weight = distance**(-1)\n",
    "                        self.result = {}\n",
    "                        for label in np.unique(self.y):\n",
    "                            self.result[label] = weight[classes == label].sum()\n",
    "                        self.labels_count.append(self.result)\n",
    "                        y_predicted.append(Counter(self.result).most_common()[0][0])\n",
    "                else:\n",
    "                    distance = np.apply_along_axis(lambda dataset_row: \n",
    "                                        self._distance_between_dataset(dataset_row, x_sample), 1, self.X)\n",
    "                    classes = self.y[distance.argsort()[:self.n_neighbors]]\n",
    "                    weight = np.array([1] * self.n_neighbors)\n",
    "                    if self.use_weights:\n",
    "                        weight = distance[distance.argsort()[:self.n_neighbors]]**(-1)\n",
    "                    self.result = {}\n",
    "                    for label in np.unique(self.y):\n",
    "                        self.result[label] = weight[classes == label].sum()\n",
    "                    self.labels_count.append(self.result)\n",
    "                    y_predicted.append(Counter(self.result).most_common()[0][0])                    \n",
    "            \n",
    "        return np.array(y_predicted)\n",
    "    \n",
    "    def _distance_between_dataset(self, x_dataset, x_new, dtype='euclidean'):\n",
    "        \"\"\"\n",
    "        dtype : distance type('euclidean', 'manhatten')\n",
    "        \"\"\"\n",
    "        if dtype == 'euclidean':\n",
    "            distance = lambda a: np.sqrt(np.sum((a - x_new)**2))\n",
    "        if dtype == 'manhatten':\n",
    "            distance = lambda a: np.abs(np.sum((a - x_new)**2))\n",
    "        if dtype == 'cosine':\n",
    "            distance = lambda a: 1 - (a.T @ x_new) / (a.T @ a * x_new.T @ x_new)\n",
    "        return distance(x_dataset)\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs prediction of probabilities of each class for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        y_predicted_proba : numpy.array, shape = (n_objects, n_classes)\n",
    "            2D array with predicted probabilities of each class. \n",
    "            Example:\n",
    "                y_predicted_proba = [[0.1, 0.9],\n",
    "                                     [0.8, 0.2], \n",
    "                                     [0.0, 1.0], \n",
    "                                     ...]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create an empty list for predictions\n",
    "        y_predicted_proba = []\n",
    "        self.predict(X)\n",
    "        for label in self.labels_count:\n",
    "            y_predicted_proba.append([label[0]/(label[1] + label[0]), \n",
    "                                      label[1]/(label[1] + label[0])])\n",
    "            \n",
    "        return np.array(y_predicted_proba) # return numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 (1 point) <br/>\n",
    "Create a matrix of object features `X` and vector of labels `y` for N=1000 objects using `sklearn.datasets.make_moons()` function from scikit-learn library. Also, set up random state in the function `random_state=42` and `noise=0.2`. To open the function description use `Shift` + `Tab` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X, y = make_moons(n_samples=1000, random_state=42, noise=0.2)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[-0.112,  0.52 ],\n",
    "                [ 1.143, -0.343]])\n",
    "assert np.array_equal(np.round(X[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 (1 point) <br/>\n",
    "\n",
    "Split the sample into train and test samples using `sklearn.model_selection.train_test_split()` function from scikit-learn library. Use `random_state = 42` and `test_size = 0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.5)\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[ 0.77 , -0.289],\n",
    "                [ 0.239,  1.041]])\n",
    "assert np.array_equal(np.round(X_train[:2], 3), ans), ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 (2 points) <br/>\n",
    "\n",
    "Modify class `KNNClassifier` above and implement `predict()` method that uses **max_dist** parameter to select neighbors like it's shown in the second figure (radius search). If there is no any object within **max_dist**, make decision based on the closest neighbor.\n",
    "\n",
    "<img src=\"img/knn2.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.24 s, sys: 25.2 ms, total: 3.27 s\n",
      "Wall time: 3.28 s\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 (2 points) <br/>\n",
    "\n",
    "There are an algorithm [kd-tree](https://en.wikipedia.org/wiki/K-d_tree) that helps to find neighbors faster. Using [scipy.spatial.cKDTree](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.cKDTree.html#scipy.spatial.cKDTree) function modify you classifier to speed up **predict** method. Use `leafsize=30` in `KDTree`. Similar to `max_dist` option, add option `use_kd_tree = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 153 ms, sys: 89 µs, total: 153 ms\n",
      "Wall time: 154 ms\n",
      "Test accuracy of KNN classifier:  0.964\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.964, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 (3 points) <br/>\n",
    "\n",
    "Now modify the **predict** method to provide prediction with neighbors weights.\n",
    "\n",
    "<img src=\"img/wv1.png\">\n",
    "\n",
    "<img src=\"img/wv2.png\">\n",
    "\n",
    "We propose you to use the following weights:\n",
    "\n",
    "$$\n",
    "w_{i} = \\frac{1}{\\rho(x, x_{i})}\n",
    "$$\n",
    "\n",
    "Similar to `max_dist` option, add option `use_weights = True/False` to your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 569 ms, sys: 99 µs, total: 569 ms\n",
      "Wall time: 569 ms\n",
      "Test accuracy of KNN classifier:  0.968\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict = knn.predict(X_test) # measure time for prediction\n",
    "\n",
    "# Import accuracy_score function\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculate accuracy for the test sample\n",
    "accuracy_test = accuracy_score(y_test, y_test_predict)\n",
    "print(\"Test accuracy of KNN classifier: \", accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "assert accuracy_test == 0.968, ('Check your solution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 (3 points) <br/>\n",
    "\n",
    "Develop **predict_proba** method of the classifier. For each object this method returns probability that the object belongs to each of the classes. \n",
    "\n",
    "For each object $x$ probability for each class is defined as:\n",
    "\n",
    "$$\n",
    "p_{c}(x) = \\frac{g_{c}(x)}{\\sum_{i=1}^{C} g_{i}(x)}\n",
    "$$\n",
    "\n",
    "where $C$ is number of classes.\n",
    "\n",
    "Then, the object has a vector of probabilities:\n",
    "\n",
    "$$\n",
    "p(x) = (p_{1}(x), p_{2}(x), ..., p_{C}(x))\n",
    "$$\n",
    "\n",
    "Use neighbors weights as in Task 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 581 ms, sys: 3.82 ms, total: 585 ms\n",
      "Wall time: 585 ms\n"
     ]
    }
   ],
   "source": [
    "# Create a class object\n",
    "knn = KNNClassifier(max_dist=0.5, use_kd_tree=True, use_weights=True)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make prediction using the trained classifier\n",
    "%time y_test_predict_proba = knn.predict_proba(X_test) # measure time for prediction\n",
    "\n",
    "# Example of the output\n",
    "y_test_predict_proba[:10, :] # the first 10 rows\n",
    "\n",
    "\n",
    "\n",
    "### Check your solution\n",
    "ans = np.array([[0.046, 0.954],\n",
    "                [0.962, 0.038]])\n",
    "assert np.array_equal(np.round(y_test_predict_proba[:2], 3), ans), ('Check your solution.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
