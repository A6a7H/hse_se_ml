{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/logo_hse_black.jpg\"></center>\n",
    "\n",
    "<h1><center>Data Analysis</center></h1>\n",
    "<h2><center>Seminar: Ensemble Learning. </center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_csv('./data/x_train.csv', sep=';')\n",
    "df_y = pd.read_csv('./data/y_train.csv', sep=';', header=None, names=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_X.values\n",
    "y = df_y['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (25289, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.90000000e+01, 1.00000000e+01, 3.00000000e+00, 1.70000000e+01,\n",
       "        2.44444444e+01, 1.00000000e+00, 5.00000000e+00, 4.00000000e-01,\n",
       "        2.65000000e+06, 1.37500000e+03, 2.10000000e+01, 2.00000000e+00],\n",
       "       [2.10000000e+01, 2.20000000e+01, 1.90000000e+01, 5.50000000e+01,\n",
       "        1.70454545e+01, 1.00000000e+00, 6.00000000e+00, 3.33333333e-01,\n",
       "        5.61400000e+06, 3.82500000e+03, 5.10000000e+01, 4.00000000e+00],\n",
       "       [5.00000000e+00, 6.00000000e+00, 1.00000000e+00, 6.00000000e+00,\n",
       "        8.40000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        8.57000000e+05, 1.15000000e+03, 1.40000000e+01, 1.00000000e+00],\n",
       "       [2.10000000e+01, 2.00000000e+00, 5.00000000e+00, 6.00000000e+00,\n",
       "        1.90000000e+01, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        1.20000000e+05, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00],\n",
       "       [4.00000000e+00, 5.00000000e+00, 1.00000000e+00, 5.00000000e+00,\n",
       "        9.60000000e+00, 0.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        8.57000000e+05, 1.07500000e+03, 1.20000000e+01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"X shape: \", X.shape)\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape:  (25289,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"y shape: \", y.shape)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split function to split the sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.5,    \n",
    "                                                    random_state=123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 (5 points)\n",
    "\n",
    "Implement Random Forest classifier as it was described in your lectures:\n",
    "\n",
    "**Input**: \n",
    "* training dataset $TDS=\\{(x_{i},y_{i}),\\,1=1,2,...N\\}$; \n",
    "* the number of trees $B$ and the size of feature subsets $m$.\n",
    "\n",
    "for $b=1,2,...B$:\n",
    "\n",
    "1. generate random training dataset $TDS^{b}$ of size $N$ by sampling $(x_{i},y_{i})$ pairs from $TDS$ with replacement (bootstrap)\n",
    "2. build a tree using $TDS^{b}$ training dataset with feature selection for each node from random subset of features of size $m$ (generated **individually for each node**).\n",
    "\n",
    "\n",
    "**Output**: $B$ trees. Classification is done using majority vote and regression using averaging of $B$ outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints:**\n",
    "- Use decision tree classifier from sklean library. You can import it with the command: `from sklearn.tree import DecisionTreeClassifier` with `max_features` option. \n",
    "- You can use `numpy.random.choice()` function to generate random subsamples to train decition tree classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let' s start with small steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First step\n",
    "\n",
    "Implement auxiliary function, which generate K random subsamples (with replacement) of X, y of size N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_subsamples(X, y, K, N):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second step\n",
    "\n",
    "Implement auxiliary function which get list of (X,y) with lengh K and fit K base_estimators. Each estimator fit from the corresponding sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_subsamples(subsamples, base_estimator):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(params):    \n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    X, y, size = params\n",
    "    subsamples = gen_subsamples(X, y, size, X.shape[0])\n",
    "    return fit_subsamples(subsamples, DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "process_count = 4\n",
    "parts = [\n",
    "    (X, y, 1000 // process_count)\n",
    "    for i in range(process_count)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(process_count) as p:\n",
    "    # every part is sent to separate processes\n",
    "    clfs = p.map(fit, parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now combine it all together in one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to modify this class #\n",
    "\n",
    "class RandomForestCalssifier(object):\n",
    "    \n",
    "    def __init__(self, n_trees=10, n_subset_features=2): # you can add more hyperparameters\n",
    "        \"\"\"\n",
    "        This is your random forest classifier.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_trees : int\n",
    "            Number of decision trees to train.\n",
    "        n_subset_features : int\n",
    "            Number of random features to used to train a decision tree.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.n_trees = n_trees\n",
    "        self.n_subset_features = n_subset_features\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the classifier.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "        y : numpy.array, shape = (n_objects)\n",
    "            1D array with the object labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs probabilities prediction for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        proba : numpy.array, shape = (n_objects, n_classes)\n",
    "            Array with predicted probabilities. \n",
    "        \"\"\"\n",
    "        \n",
    "        proba = np.random.rand(len(X), 2) # for 2 classes\n",
    "        \n",
    "        return proba\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        This methods performs labels prediction for new objects.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy.array, shape = (n_objects, n_features)\n",
    "            Matrix of objects that are described by their input features.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        labels : numpy.array, shape = (n_objects)\n",
    "            1D array with predicted labels. \n",
    "            For the classification labels are integers in {0, 1, 2, ...}.\n",
    "        \"\"\"\n",
    "        \n",
    "        labels = np.random.randint(low=0, high=2, size=len(X)) # for 2 classes\n",
    "        \n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestCalssifier(n_trees=10, n_subset_features=2)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "y_test_predict[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 (1 point)\n",
    "\n",
    "Plot ROC curve on the test sample for your random forest classifier. Also, claculate ROC AUC value. Use `RandomForestClassifier.predict_proba()` method.\n",
    "\n",
    "Hints:\n",
    "- You can use `sklearn.metrics.roc_curve` frunction to calculate ROC curve.\n",
    "- `sklearn.metrics.roc_auc_score` function helps you to calculate ROC AUC value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 (2 points)\n",
    "\n",
    "Plot dependecy of ROC AUC value from number of trees (`n_trees`) in your random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code is here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 (2 points)\n",
    "\n",
    "Plot dependecy of ROC AUC value from `n_subset_features` of your random forest classifier. Use `n_trees=100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code is here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
